{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function, division\n", "import scipy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.datasets import mnist\n", "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n", "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n", "from keras.layers.advanced_activations import LeakyReLU\n", "from keras.layers.convolutional import UpSampling2D, Conv2D\n", "from keras.models import Sequential, Model\n", "from keras.optimizers import RMSprop, Adam\n", "from keras.utils import to_categorical\n", "import keras.backend as K"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DUALGAN():\n", "    def __init__(self):\n", "        self.img_rows = 28\n", "        self.img_cols = 28\n", "        self.channels = 1\n", "        self.img_dim = self.img_rows*self.img_cols\n", "        optimizer = Adam(0.0002, 0.5)\n\n", "        # Build and compile the discriminators\n", "        self.D_A = self.build_discriminator()\n", "        self.D_A.compile(loss=self.wasserstein_loss,\n", "            optimizer=optimizer,\n", "            metrics=['accuracy'])\n", "        self.D_B = self.build_discriminator()\n", "        self.D_B.compile(loss=self.wasserstein_loss,\n", "            optimizer=optimizer,\n", "            metrics=['accuracy'])\n\n", "        #-------------------------\n", "        # Construct Computational\n", "        #   Graph of Generators\n", "        #-------------------------\n\n", "        # Build the generators\n", "        self.G_AB = self.build_generator()\n", "        self.G_BA = self.build_generator()\n\n", "        # For the combined model we will only train the generators\n", "        self.D_A.trainable = False\n", "        self.D_B.trainable = False\n\n", "        # The generator takes images from their respective domains as inputs\n", "        imgs_A = Input(shape=(self.img_dim,))\n", "        imgs_B = Input(shape=(self.img_dim,))\n\n", "        # Generators translates the images to the opposite domain\n", "        fake_B = self.G_AB(imgs_A)\n", "        fake_A = self.G_BA(imgs_B)\n\n", "        # The discriminators determines validity of translated images\n", "        valid_A = self.D_A(fake_A)\n", "        valid_B = self.D_B(fake_B)\n\n", "        # Generators translate the images back to their original domain\n", "        recov_A = self.G_BA(fake_B)\n", "        recov_B = self.G_AB(fake_A)\n\n", "        # The combined model  (stacked generators and discriminators)\n", "        self.combined = Model(inputs=[imgs_A, imgs_B], outputs=[valid_A, valid_B, recov_A, recov_B])\n", "        self.combined.compile(loss=[self.wasserstein_loss, self.wasserstein_loss, 'mae', 'mae'],\n", "                            optimizer=optimizer,\n", "                            loss_weights=[1, 1, 100, 100])\n", "    def build_generator(self):\n", "        X = Input(shape=(self.img_dim,))\n", "        model = Sequential()\n", "        model.add(Dense(256, input_dim=self.img_dim))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Dropout(0.4))\n", "        model.add(Dense(512))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Dropout(0.4))\n", "        model.add(Dense(1024))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Dropout(0.4))\n", "        model.add(Dense(self.img_dim, activation='tanh'))\n", "        X_translated = model(X)\n", "        return Model(X, X_translated)\n", "    def build_discriminator(self):\n", "        img = Input(shape=(self.img_dim,))\n", "        model = Sequential()\n", "        model.add(Dense(512, input_dim=self.img_dim))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(Dense(256))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Dense(1))\n", "        validity = model(img)\n", "        return Model(img, validity)\n", "    def sample_generator_input(self, X, batch_size):\n", "        # Sample random batch of images from X\n", "        idx = np.random.randint(0, X.shape[0], batch_size)\n", "        return X[idx]\n", "    def wasserstein_loss(self, y_true, y_pred):\n", "        return K.mean(y_true * y_pred)\n", "    def train(self, epochs, batch_size=128, sample_interval=50):\n\n", "        # Load the dataset\n", "        (X_train, _), (_, _) = mnist.load_data()\n\n", "        # Rescale -1 to 1\n", "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n\n", "        # Domain A and B (rotated)\n", "        X_A = X_train[:int(X_train.shape[0]/2)]\n", "        X_B = scipy.ndimage.interpolation.rotate(X_train[int(X_train.shape[0]/2):], 90, axes=(1, 2))\n", "        X_A = X_A.reshape(X_A.shape[0], self.img_dim)\n", "        X_B = X_B.reshape(X_B.shape[0], self.img_dim)\n", "        clip_value = 0.01\n", "        n_critic = 4\n\n", "        # Adversarial ground truths\n", "        valid = -np.ones((batch_size, 1))\n", "        fake = np.ones((batch_size, 1))\n", "        for epoch in range(epochs):\n\n", "            # Train the discriminator for n_critic iterations\n", "            for _ in range(n_critic):\n", "                # ----------------------\n", "                #  Train Discriminators\n", "                # ----------------------\n", "                # Sample generator inputs\n", "                imgs_A = self.sample_generator_input(X_A, batch_size)\n", "                imgs_B = self.sample_generator_input(X_B, batch_size)\n", "                # Translate images to their opposite domain\n", "                fake_B = self.G_AB.predict(imgs_A)\n", "                fake_A = self.G_BA.predict(imgs_B)\n", "                # Train the discriminators\n", "                D_A_loss_real = self.D_A.train_on_batch(imgs_A, valid)\n", "                D_A_loss_fake = self.D_A.train_on_batch(fake_A, fake)\n", "                D_B_loss_real = self.D_B.train_on_batch(imgs_B, valid)\n", "                D_B_loss_fake = self.D_B.train_on_batch(fake_B, fake)\n", "                D_A_loss = 0.5 * np.add(D_A_loss_real, D_A_loss_fake)\n", "                D_B_loss = 0.5 * np.add(D_B_loss_real, D_B_loss_fake)\n", "                # Clip discriminator weights\n", "                for d in [self.D_A, self.D_B]:\n", "                    for l in d.layers:\n", "                        weights = l.get_weights()\n", "                        weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n", "                        l.set_weights(weights)\n\n", "            # ------------------\n", "            #  Train Generators\n", "            # ------------------\n\n", "            # Train the generators\n", "            g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A, imgs_B])\n\n", "            # Plot the progress\n", "            print (\"%d [D1 loss: %f] [D2 loss: %f] [G loss: %f]\" \\\n", "                % (epoch, D_A_loss[0], D_B_loss[0], g_loss[0]))\n\n", "            # If at save interval => save generated image samples\n", "            if epoch % sample_interval == 0:\n", "                self.save_imgs(epoch, X_A, X_B)\n", "    def save_imgs(self, epoch, X_A, X_B):\n", "        r, c = 4, 4\n\n", "        # Sample generator inputs\n", "        imgs_A = self.sample_generator_input(X_A, c)\n", "        imgs_B = self.sample_generator_input(X_B, c)\n\n", "        # Images translated to their opposite domain\n", "        fake_B = self.G_AB.predict(imgs_A)\n", "        fake_A = self.G_BA.predict(imgs_B)\n", "        gen_imgs = np.concatenate([imgs_A, fake_B, imgs_B, fake_A])\n", "        gen_imgs = gen_imgs.reshape((r, c, self.img_rows, self.img_cols, 1))\n\n", "        # Rescale images 0 - 1\n", "        gen_imgs = 0.5 * gen_imgs + 0.5\n", "        fig, axs = plt.subplots(r, c)\n", "        cnt = 0\n", "        for i in range(r):\n", "            for j in range(c):\n", "                axs[i,j].imshow(gen_imgs[i, j, :,:,0], cmap='gray')\n", "                axs[i,j].axis('off')\n", "                cnt += 1\n", "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n", "        plt.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    gan = DUALGAN()\n", "    gan.train(epochs=30000, batch_size=32, sample_interval=200)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}