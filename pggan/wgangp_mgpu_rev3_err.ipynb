{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2h over -> 40min by Multi GPU!\n",
    "\n",
    "TASK\n",
    "d_loss　これまでと比較できるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Reshape, Flatten, Activation, Lambda\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "import shutil, os, sys, io, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('/home/k_yonhon/py/Keras-GAN/pggan/')\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from tensor_board_logger import TensorBoardLogger\n",
    "from layer_visualizer import LayerVisualizer\n",
    "\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "\n",
    "gpu_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        # ---------------------\n",
    "        #  for log on TensorBoard\n",
    "        # ---------------------\n",
    "        target_dir = \"./my_log_dir\"\n",
    "        shutil.rmtree(target_dir, ignore_errors=True)\n",
    "        os.mkdir(target_dir)\n",
    "        self.logger = TensorBoardLogger(log_dir=target_dir)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Parameter\n",
    "        # ---------------------\n",
    "        self.resume = 0\n",
    "        \n",
    "        self.n_critic = 5\n",
    "        self.λ = 10\n",
    "        \n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.input_rows = 4\n",
    "        self.input_cols = 4\n",
    "        self.latent_dim = 128  # Noiseの次元\n",
    "        optimizer = Adam(lr=0.0005, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Build model\n",
    "        # ---------------------\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            if self.resume == 0:\n",
    "                self.critic = self.build_critic()\n",
    "                self.generator = self.build_generator()\n",
    "            else:\n",
    "                self.critic = load_model('./saved_model/wgangp32_disc_model_'+str(self.resume)+'epoch.h5')\n",
    "                self.generator = load_model('./saved_model/wgangp32_gen_model_'+str(self.resume)+'epoch.h5')\n",
    "                \n",
    "            #  Load pretrained weights\n",
    "            pre_gen = load_model('./saved_model/wgangp16_gen_model.h5')\n",
    "            for i, layer in enumerate(self.generator.layers[1].layers):\n",
    "                if i in [i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]:\n",
    "                    layer.set_weights(pre_gen.layers[1].layers[i].get_weights())\n",
    "\n",
    "            pre_critic = load_model('./saved_model/wgangp16_disc_model.h5')\n",
    "            for i, layer in enumerate(self.critic.layers[1].layers):\n",
    "                j = i - len(self.critic.layers[1].layers)\n",
    "                if j in [-i for i in range(int(math.log(self.img_rows / self.input_rows, 2)) * 2, 0, -2)]:\n",
    "                    layer.set_weights(pre_critic.layers[1].layers[j].get_weights())\n",
    "                    layer.trainable = False\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "        \n",
    "        # Construct weighted average between real and fake images\n",
    "        ϵ_input = Input(shape=(1,))\n",
    "        # interpolated_img = K.dot(ϵ_input, real_img) + K.dot((1-ϵ_input), fake_img)\n",
    "        # interpolated_img = K.dot(ϵ_input, real_img)\n",
    "        self.interpolate = self.build_interpolate()\n",
    "        mix_img = self.interpolate(ϵ_input, real_img, fake_img)\n",
    "        ϵ_input = Input(shape=(1,))\n",
    "        # mix_img = Lambda(lambda ϵ_input: ϵ_input * real_img + (1-ϵ_input) * fake_img, output_shape=self.img_shape)(ϵ_input)\n",
    "        interpolated_img = Model(inputs=[ϵ_input, real_img, fake_img], outputs=[mix_img])\n",
    "        \n",
    "        # Discriminator determines validity of the real and fake and interpolated images\n",
    "        valid = self.critic(real_img)\n",
    "        fake = self.critic(fake_img)\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss, \n",
    "                                  averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "        \n",
    "        self.critic_model = Model(inputs=[real_img, z_disc, ϵ_input], \n",
    "                                  outputs=[valid, fake, validity_interpolated])\n",
    "        if gpu_count > 1:\n",
    "            self.critic_model = multi_gpu_model(self.critic_model, gpus=gpu_count)\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                        self.wasserstein_loss,\n",
    "                                        partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, self.λ])\n",
    "        print('Critic Summary:')\n",
    "        self.critic.summary()\n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        \n",
    "        self.generator.trainable = True\n",
    "        for i, layer in enumerate(self.generator.layers[1].layers):\n",
    "            if i in [i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]:\n",
    "                layer.trainable = False\n",
    "                \n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(self.latent_dim,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        if gpu_count > 1:\n",
    "            self.generator_model = multi_gpu_model(self.generator_model, gpus=gpu_count)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "        print('Genarator Summary:')\n",
    "        self.generator.summary()\n",
    "        \n",
    "        # self.critic_model = tf.keras.estimator.model_to_estimator(keras_model=self.critic_model)\n",
    "        # self.generator_model = tf.keras.estimator.model_to_estimator(keras_model=self.generator_model)\n",
    "            \n",
    "    def compute_gradients(self, tensor, var_list):\n",
    "        grads = tf.gradients(tensor, var_list)\n",
    "        return [grad if grad is not None else tf.zeros_like(var) for var, grad in zip(var_list, grads)]\n",
    "    \n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        gradients_sqr = K.square(self.compute_gradients(y_pred, [averaged_samples])[0])\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        return K.mean(gradient_penalty)\n",
    "   \n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_interpolate(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            ϵ_input = Input(shape=(1,))\n",
    "            real_img = Input(shape=self.img_shape)\n",
    "            fake_img = Input(shape=self.img_shape)\n",
    "            mix_img = Lambda(lambda ϵ_input, real_img, fake_img: ϵ_input * real_img + (1-ϵ_input) * fake_img)\n",
    "            return Model(inputs=[ϵ_input, real_img, fake_img], outputs=[mix_img])\n",
    "\n",
    "    def build_generator(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            model = Sequential()\n",
    "            model.add(Reshape((self.input_rows, self.input_cols, int(self.latent_dim / (self.input_rows * self.input_cols))), \n",
    "                              input_shape=(self.latent_dim,)\n",
    "                             ))\n",
    "\n",
    "            model.add(Conv2DTranspose(512, (3, 3), strides=1, padding='same',\n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))      \n",
    "\n",
    "            for _ in range(int(math.log(self.img_rows / self.input_rows, 2))):\n",
    "                model.add(Conv2DTranspose(512, (3, 3), strides=2, padding='same', \n",
    "                                         kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                         ))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(256, (3, 3), strides=1, padding='same', \n",
    "                                      kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                      ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(128, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(64, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(32, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(16, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(3, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))                \n",
    "            model.add(Activation(\"tanh\"))\n",
    "\n",
    "            noise = Input(shape=(self.latent_dim,))\n",
    "            img = model(noise)\n",
    "            return Model(noise, img)\n",
    "    \n",
    "    def build_critic(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(16, (1, 1), strides=1, input_shape=self.img_shape, padding=\"valid\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(32, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(64, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(128, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(256, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(512, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            for _ in range(int(math.log(self.img_rows / self.input_rows, 2))):\n",
    "                model.add(Conv2D(512, (3, 3), strides=2, padding=\"same\",\n",
    "                                 kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                ))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(1, (4, 4), strides=1, padding=\"valid\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(Flatten())\n",
    "\n",
    "            img = Input(shape=self.img_shape)\n",
    "            validity = model(img)\n",
    "            return Model(img, validity)\n",
    "    \n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "        # ---------------------\n",
    "        #  Load the dataset\n",
    "        # ---------------------      \n",
    "        # Original dataset\n",
    "        X_train = np.load('../datasets/lfw32.npz')['arr_0']\n",
    "        X_train = X_train / 127.5 - 1.0   # Rescale -1 to 1\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1))\n",
    "                \n",
    "        for epoch in tqdm(range(self.resume, self.resume + epochs + 1)):\n",
    "            for _ in range(self.n_critic):\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                epsilon = np.random.uniform(0, 1, (batch_size, 1))\n",
    "                \n",
    "                # Train the critic https://keras.io/ja/models/model/#train_on_batch\n",
    "                d_loss = self.critic_model.train_on_batch([imgs, noise, epsilon], \n",
    "                                                          [valid, fake, dummy])\n",
    "                d_loss = d_loss[0]\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Log on TensorBoard\n",
    "            # ---------------------\n",
    "            # Backup Model\n",
    "            # if epoch != 0 and epoch % 1000 == 0:\n",
    "            #     self.critic.save('./saved_model/wgangp32_disc_model_'+str(epoch+self.resume)+'epoch.h5')\n",
    "            #     self.generator.save('./saved_model/wgangp32_gen_model_'+str(epoch+self.resume)+'epoch.h5')\n",
    "            \n",
    "            # Save Loss & Histgram\n",
    "            logs = {\n",
    "                \"Discriminator/loss\": d_loss,\n",
    "                \"Generator/loss\": g_loss,\n",
    "            }\n",
    "\n",
    "            histograms = {}\n",
    "            for layer in self.critic.layers[1].layers:\n",
    "                for i in range(len(layer.get_weights())):\n",
    "                    if \"conv\" in layer.name or \"dense\" in layer.name:\n",
    "                        name = layer.name + \"/\" + str(i)\n",
    "                        value = layer.get_weights()[i]\n",
    "                        histograms[name] = value\n",
    "            self.logger.log(logs=logs, histograms=histograms, epoch=epoch+self.resume)\n",
    "            \n",
    "            # Save generated image samples\n",
    "            if epoch+self.resume == 1000 or epoch+self.resume == 2000 or (epoch+self.resume) % sample_interval == 0:\n",
    "                fig, name = self.sample_images(epoch+self.resume)\n",
    "                images = {name: fig}\n",
    "                self.logger.log(images=images, epoch=epoch+self.resume)\n",
    "                print(\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss, g_loss))\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                if self.channels == 1:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap=\"gray\")\n",
    "                else:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, :self.channels], cmap=\"gray\")\n",
    "                axs[i, j].axis(\"off\")\n",
    "                cnt += 1\n",
    "        name = str(epoch) + \".png\"\n",
    "        return fig, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Lambda object at 0x7fcc92b00b38>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-832444229705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGANGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-dfcca16b5b7f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# interpolated_img = K.dot(ϵ_input, real_img) + K.dot((1-ϵ_input), fake_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# interpolated_img = K.dot(ϵ_input, real_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_interpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mmix_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mϵ_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mϵ_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dfcca16b5b7f>\u001b[0m in \u001b[0;36mbuild_interpolate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mfake_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mmix_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mϵ_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_img\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mϵ_input\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mϵ_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfake_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mϵ_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmix_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m                                  \u001b[0;34m'the output of a Keras `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                                  \u001b[0;34m'(thus holding past layer metadata). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                                  'Found: ' + str(x))\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Lambda object at 0x7fcc92b00b38>"
     ]
    }
   ],
   "source": [
    "wgan = WGANGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10001 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer model_57 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[ 0.65793702, -0.75805358, -0.11626432, ..., -0.98515984,\n        -0.58734277, -0.36988764],\n       [ 0.69364593,  0.59771056, -0.32158228, ...,  0.00577185,\n         0.95836626, -0.22131529],\n       [-0.63888897,  1.06703683, -0.28133707, ...,  0.67263259,\n         1.00769612,  0.3193566 ],\n       ...,\n       [ 1.88963822,  1.03870942, -0.94576235, ...,  2.17268146,\n         0.54735567, -1.18917328],\n       [ 0.63212721, -1.02561557, -0.55356255, ...,  0.32797021,\n         0.2961781 , -0.56840746],\n       [ 0.86339462,  2.1592337 , -1.0359202 , ...,  0.19962849,\n         0.84791822, -0.07980201]])]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 474\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d2a09928e2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-2dc47bb54f00>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;31m# Sample generator input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0minterpolated_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# Train the critic https://keras.io/ja/models/model/#train_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer model_57 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[ 0.65793702, -0.75805358, -0.11626432, ..., -0.98515984,\n        -0.58734277, -0.36988764],\n       [ 0.69364593,  0.59771056, -0.32158228, ...,  0.00577185,\n         0.95836626, -0.22131529],\n       [-0.63888897,  1.06703683, -0.28133707, ...,  0.67263259,\n         1.00769612,  0.3193566 ],\n       ...,\n       [ 1.88963822,  1.03870942, -0.94576235, ...,  2.17268146,\n         0.54735567, -1.18917328],\n       [ 0.63212721, -1.02561557, -0.55356255, ...,  0.32797021,\n         0.2961781 , -0.56840746],\n       [ 0.86339462,  2.1592337 , -1.0359202 , ...,  0.19962849,\n         0.84791822, -0.07980201]])]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "wgan.train(epochs=10000, batch_size=32, sample_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_34\n",
      "leaky_re_lu_61\n",
      "conv2d_35\n",
      "leaky_re_lu_62\n",
      "conv2d_36\n",
      "leaky_re_lu_63\n",
      "conv2d_37\n",
      "leaky_re_lu_64\n",
      "conv2d_38\n",
      "leaky_re_lu_65\n",
      "conv2d_39\n",
      "leaky_re_lu_66\n",
      "conv2d_40\n",
      "leaky_re_lu_67\n",
      "conv2d_41\n",
      "leaky_re_lu_68\n",
      "conv2d_42\n",
      "leaky_re_lu_69\n",
      "conv2d_43\n",
      "leaky_re_lu_70\n",
      "conv2d_44\n",
      "flatten_4\n"
     ]
    }
   ],
   "source": [
    "for layer in wgan.critic.layers[1].layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(int(math.log(self.img_rows / self.input_rows, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "list = [i for i in range(1, int(math.log(64 / 4, 2)) * 2, 2)]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8, -6, -4, -2]\n"
     ]
    }
   ],
   "source": [
    "list = [-i for i in range(int(math.log(64 / 4, 2)) * 2, 0, -2)]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]\n",
    "[-i for i in range(int(math.log(self.img_rows / self.input_rows, 2)) * 2, 0, -2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
