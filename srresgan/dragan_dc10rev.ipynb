{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "100%|██████████| 10001/10001 [43:41<00:00,  3.84it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Reshape, Flatten, Activation, UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import ReLU, LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dense, Add, Lambda, Concatenate\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.engine.network import Network, Layer\n",
    "from keras.initializers import TruncatedNormal\n",
    "\n",
    "import shutil, os, sys, io, random, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('/home/k_yonhon/py/Keras-GAN/dragan/')\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from tensor_board_logger import TensorBoardLogger\n",
    "from wasserstein_loss import WassersteinLoss, GradientPenaltyLoss, loss_func_dcgan_dis_real, loss_func_dcgan_dis_fake, CommonVanillaLoss\n",
    "\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "\n",
    "# ---------------------\n",
    "#  Parameter\n",
    "# ---------------------\n",
    "gpu_count = 1\n",
    "resume = 0\n",
    "dataset = np.load('../datasets/lfw32.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, base_name, block_num, initializer, num_channels=128, is_D=False):\n",
    "    y = Conv2D(num_channels, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializer, use_bias=False,\n",
    "               name=base_name + \"_resblock\" + str(block_num) + \"_conv1\")(x)\n",
    "    if not is_D:\n",
    "        y = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_resblock\" + str(block_num) + \"_bn1\")(y, training=1)\n",
    "        y = Activation(\"relu\")(y)\n",
    "    else:\n",
    "        y = LeakyReLU(0.2)(y)\n",
    "    y = Conv2D(num_channels, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializer, use_bias=False,\n",
    "               name=base_name + \"_resblock\" + str(block_num) + \"_conv2\")(y)\n",
    "    if not is_D:\n",
    "        y = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_resblock\" + str(block_num) + \"_bn2\")(y, training=1)\n",
    "    return Add()([x, y])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRAGAN():\n",
    "    def __init__(self, dataset, gpu_count=1, resume=0):\n",
    "        # ---------------------\n",
    "        #  Parameter\n",
    "        # ---------------------\n",
    "        self.dataset = dataset\n",
    "        self.gpu_count = gpu_count\n",
    "        self.resume = resume\n",
    "                \n",
    "        self.img_rows = dataset.shape[1]\n",
    "        self.img_cols = dataset.shape[2]\n",
    "        self.channels = dataset.shape[3]\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        self.input_rows = 2\n",
    "        self.input_cols = 2\n",
    "        self.latent_dim = 128  # Noise dim\n",
    "        \n",
    "        self.n_critic = 5\n",
    "        self.λ = 10\n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Load models\n",
    "        # ---------------------\n",
    "        self.critic = self.build_critic()\n",
    "        self.generator = self.build_generator()\n",
    "        if self.resume != 0:\n",
    "            self.critic = load_model('./saved_model/dragan'+str(self.λ)+'_critic_'+str(self.resume)+'epoch.h5')\n",
    "            self.generator = load_model('./saved_model/dragan'+str(self.λ)+'_gen_'+str(self.resume)+'epoch.h5')  \n",
    "        \n",
    "        #-------------------------------\n",
    "        # Compile Critic\n",
    "        #-------------------------------    \n",
    "        generated_samples = Input(shape=self.img_shape) \n",
    "        critic_output_from_generated_samples = self.critic(generated_samples)\n",
    "        \n",
    "        real_samples = Input(shape=self.img_shape)        \n",
    "        critic_output_from_real_samples = self.critic(real_samples)\n",
    "\n",
    "        averaged_samples = Input(shape=self.img_shape)\n",
    "        critic_output_from_averaged_samples = self.critic(averaged_samples)\n",
    "\n",
    "        partial_gp_loss = partial(GradientPenaltyLoss,\n",
    "                                  averaged_samples=averaged_samples,\n",
    "                                  gradient_penalty_weight=self.λ)\n",
    "        # Functions need names or Keras will throw an error\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "        self.critic_model = Model(inputs=[generated_samples, \n",
    "                                          real_samples,\n",
    "                                          averaged_samples],\n",
    "                                  outputs=[critic_output_from_generated_samples, \n",
    "                                           critic_output_from_real_samples,\n",
    "                                           critic_output_from_averaged_samples])\n",
    "        \n",
    "        # loss_dis = loss_func_dcgan_dis_real(y_dis) + loss_func_dcgan_dis_fake(y_fake) + loss_grad\n",
    "        # loss_gen = loss_func_dcgan_dis_real(y_fake)\n",
    "        \n",
    "        if self.gpu_count > 1:\n",
    "            self.critic_model = multi_gpu_model(self.critic_model, gpus=self.gpu_count)\n",
    "        self.critic_model.compile(optimizer=optimizer, \n",
    "                                  loss=[CommonVanillaLoss, \n",
    "                                        CommonVanillaLoss, \n",
    "                                        partial_gp_loss])\n",
    "        \n",
    "        # print('Critic Summary:')\n",
    "        # self.critic.summary()       \n",
    "        \n",
    "        #-------------------------------\n",
    "        # Compile Generator\n",
    "        #-------------------------------\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "                    \n",
    "        generator_input = Input(shape=(self.latent_dim,))\n",
    "        generator_layers = self.generator(generator_input)\n",
    "        critic_layers_for_generator = self.critic(generator_layers)\n",
    "        \n",
    "        self.generator_model = Model(inputs=[generator_input], \n",
    "                                     outputs=[critic_layers_for_generator])\n",
    "        if self.gpu_count > 1:\n",
    "            self.generator_model = multi_gpu_model(self.generator_model, gpus=self.gpu_count)\n",
    "        self.generator_model.compile(optimizer=optimizer,\n",
    "                                     loss=CommonVanillaLoss)        \n",
    "\n",
    "        # print('Genarator Summary:')\n",
    "        # self.generator.summary()     \n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        latent_dim = self.latent_dim\n",
    "        image_shape = self.img_shape\n",
    "        num_res_blocks = 3\n",
    "        base_name = \"generator\"\n",
    "        initializer = TruncatedNormal(mean=0, stddev=0.2, seed=42)\n",
    "        \n",
    "        in_x = Input(shape=(latent_dim,))\n",
    "\n",
    "        h, w, c = image_shape\n",
    "\n",
    "        x = Dense(64*8*h//8*w//8, activation=\"relu\", name=base_name+\"_dense\")(in_x)\n",
    "        x = Reshape((h//8, w//8, -1))(x)\n",
    "\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64*4, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializer,\n",
    "                   use_bias=False,name=base_name + \"_conv1\")(x)\n",
    "        x = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_bn1\")(x, training=1)\n",
    "\n",
    "        for i in range(num_res_blocks):\n",
    "            x = residual_block(x, base_name=base_name+\"res1\", block_num=i, initializer=initializer, num_channels=64*4)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # size//8→size//4→size//2→size\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64*2, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializer,\n",
    "                   use_bias=False,name=base_name + \"_conv2\")(x)\n",
    "        x = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_bn2\")(x, training=1)\n",
    "\n",
    "        for i in range(num_res_blocks):\n",
    "            x = residual_block(x, base_name=base_name+\"res2\", block_num=i, initializer=initializer, num_channels=64*2)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64*1, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializer,\n",
    "                   use_bias=False,name=base_name + \"_conv3\")(x)\n",
    "        x = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_bn3\")(x,training=1)\n",
    "\n",
    "        for i in range(num_res_blocks):\n",
    "            x = residual_block(x, base_name=base_name+\"res3\", block_num=i, initializer=initializer, num_channels=64*1)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        x = Conv2D(3, kernel_size=3, strides=1, padding=\"same\", kernel_initializer=initializer, activation=\"tanh\",\n",
    "                   use_bias=False,name=base_name + \"_conv4\")(x)\n",
    "        out = Activation(\"tanh\")(x)\n",
    "        \n",
    "        model = Model(in_x, out, name=base_name)\n",
    "        print('Generator Summary:')\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def build_critic(self):\n",
    "        input_shape = self.img_shape\n",
    "        base_name = \"discriminator\"\n",
    "        num_res_blocks = 0\n",
    "        is_D = True\n",
    "        use_res = True\n",
    "        \n",
    "        initializer_d = TruncatedNormal(mean=0, stddev=0.1, seed=42)\n",
    "\n",
    "        D = in_D = Input(shape=input_shape)\n",
    "        D = Conv2D(64, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=initializer_d,\n",
    "                   use_bias=False,\n",
    "                   name=base_name + \"_conv1\")(D)\n",
    "        \"\"\"\n",
    "        if use_res:\n",
    "            for i in range(3):\n",
    "                D = residual_block(D, base_name=base_name+\"res1\", block_num=i,\n",
    "                                   initializer=initializer_d, num_channels=64, is_D=is_D)\n",
    "        \"\"\"\n",
    "        D = LeakyReLU(0.2)(D)\n",
    "\n",
    "        D = Conv2D(128, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=initializer_d,\n",
    "                   use_bias=False,\n",
    "                   name=base_name + \"_conv2\")(D)\n",
    "        \"\"\"\n",
    "        if use_res:\n",
    "            for i in range(3):\n",
    "                D = residual_block(D, base_name=base_name+\"res2\", block_num=i,\n",
    "                                   initializer=initializer_d, num_channels=128, is_D=is_D)\n",
    "        \"\"\"\n",
    "        #D = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_bn1\")(D, training=1)\n",
    "        D = LeakyReLU(0.2)(D)\n",
    "\n",
    "        D = Conv2D(256, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=initializer_d,\n",
    "                   use_bias=False,\n",
    "                   name=base_name + \"_conv3\")(D)\n",
    "        #D = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_bn2\")(D, training=1)\n",
    "\n",
    "        if use_res:\n",
    "            for i in range(5):\n",
    "                D = residual_block(D, base_name=base_name+\"res3\", block_num=i,\n",
    "                                   initializer=initializer_d, num_channels=256, is_D=is_D)\n",
    "        D = LeakyReLU(0.2)(D)\n",
    "\n",
    "        D = Conv2D(512, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=initializer_d,\n",
    "                   use_bias=False,\n",
    "                   name=base_name + \"_conv4\")(D)\n",
    "        \"\"\"\n",
    "        if use_res:\n",
    "            for i in range(5):\n",
    "                D = residual_block(D, base_name=base_name+\"res4\", block_num=i,\n",
    "                                   initializer=initializer_d, num_channels=512, is_D=is_D)\n",
    "        \"\"\"\n",
    "        #D = BatchNormalization(momentum=0.9, epsilon=1e-5, name=base_name + \"_bn3\")(D, training=1)\n",
    "        D = LeakyReLU(0.2)(D)\n",
    "        D = Conv2D(1, kernel_size=1, strides=1, padding=\"same\", kernel_initializer=initializer_d,\n",
    "                   use_bias=False,\n",
    "                   name=base_name + \"_conv5\")(D)\n",
    "\n",
    "        out = Flatten()(D)\n",
    "        # out = Dense(units=1, activation=None, name=base_name + \"_out\")(D)\n",
    "        \n",
    "        model = Model(in_D, out, name=base_name)\n",
    "        print('Critic Summary:')\n",
    "        model.summary()\n",
    "        return model \n",
    "\n",
    "    def train(self, epochs, batch_size, sample_interval=5000):       \n",
    "        # ---------------------\n",
    "        #  for Logging\n",
    "        # ---------------------\n",
    "        target_dir = \"./search/my_log_dir_dragan10\"\n",
    "        seed = 0\n",
    "        image_num = 5       \n",
    "        np_samples = []\n",
    "        \n",
    "        # Load suspended training weights\n",
    "        if self.resume != 0:\n",
    "            np_samples_npz = np.load('./saved_model/dragan'+str(self.λ)+'_np_'+str(self.resume)+'epoch.npz')\n",
    "            for i, np_sample in enumerate(np_samples_npz):\n",
    "                np_samples.append(np_sample)\n",
    "        else:            \n",
    "            shutil.rmtree(target_dir, ignore_errors=True)\n",
    "            os.mkdir(target_dir)\n",
    "                \n",
    "        self.logger = TensorBoardLogger(log_dir=target_dir)            \n",
    "        \n",
    "        # ---------------------\n",
    "        #  Training\n",
    "        # ---------------------\n",
    "        # Rescale the dataset -1 to 1 \n",
    "        X_train = self.dataset / 127.5 - 1.0\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        minus = -np.ones((batch_size, 1), dtype=np.float32)\n",
    "        plus = np.ones((batch_size, 1), dtype=np.float32)\n",
    "        dummy = np.zeros((batch_size, 1), dtype=np.float32)\n",
    "\n",
    "        for epoch in tqdm(range(self.resume, self.resume + epochs + 1)):\n",
    "            for _ in range(self.n_critic):\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise, batch_size=batch_size)\n",
    "                \n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                real_imgs = X_train[idx]\n",
    "                               \n",
    "                # ε = np.random.uniform(size=(batch_size, 1,1,1))\n",
    "                # ave_imgs = ε * real_imgs + (1-ε) * gen_imgs\n",
    "                ave_imgs = real_imgs + 0.5 * np.random.random(real_imgs.shape) * real_imgs.std() \n",
    "                \n",
    "                # Train Critic\n",
    "                d_loss = self.critic_model.train_on_batch([gen_imgs, real_imgs, ave_imgs], \n",
    "                                                          [minus, plus, dummy])\n",
    "\n",
    "            # Train Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            g_loss = self.generator_model.train_on_batch(noise, plus)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Logging\n",
    "            # ---------------------\n",
    "            # Backup Model\n",
    "            '''\n",
    "            if epoch != resume and epoch % sample_interval == 0:\n",
    "                self.critic.save('./saved_model/dragan'+str(self.λ)+'_critic_'+str(epoch)+'epoch.h5')\n",
    "                self.generator.save('./saved_model/dragan'+str(self.λ)+'_gen_'+str(epoch)+'epoch.h5')\n",
    "                np.savez_compressed('./saved_model/dragan'+str(self.λ)+'_np_'+str(epoch)+'epoch.npz', np_samples)\n",
    "            '''\n",
    "            # Log Loss & Histgram\n",
    "            logs = {\n",
    "                \"loss/Critic\": d_loss[0],\n",
    "                \"loss/Generator\": g_loss,\n",
    "                \"loss_Critic/D_gen\": d_loss[1],\n",
    "                \"loss_Critic/D_real\": d_loss[2],\n",
    "                \"loss_Critic/gradient_penalty\": d_loss[3],\n",
    "                \"loss_Critic/total_loss\": d_loss[1] + d_loss[2] + d_loss[3],                \n",
    "            }\n",
    "\n",
    "            histograms = {}\n",
    "            '''\n",
    "            for layer in self.critic.layers[1].layers:\n",
    "                for i in range(len(layer.get_weights())):\n",
    "                    if \"conv\" in layer.name or \"dense\" in layer.name:\n",
    "                        name = layer.name + \"/\" + str(i)\n",
    "                        value = layer.get_weights()[i]\n",
    "                        histograms[name] = value\n",
    "            '''\n",
    "            self.logger.log(logs=logs, histograms=histograms, epoch=epoch)\n",
    "            \n",
    "            # Log generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                np.random.seed(seed)\n",
    "                noise = np.random.normal(0, 1, (image_num, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "                gen_imgs = ((0.5 * gen_imgs + 0.5) * 255).astype(np.uint8)\n",
    "                np_samples.append(gen_imgs)\n",
    "                '''\n",
    "                fig, name = self.sample_images(epoch)\n",
    "                images = {epoch: fig}\n",
    "                self.logger.log(images=images, epoch=epoch)\n",
    "                '''\n",
    "                print(\"%d [C loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "                \n",
    "        return np_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic Summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_conv1 (Conv2D)    (None, 16, 16, 64)   3072        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 64)   0           discriminator_conv1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_conv2 (Conv2D)    (None, 8, 8, 128)    131072      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 8, 8, 128)    0           discriminator_conv2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_conv3 (Conv2D)    (None, 4, 4, 256)    524288      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock0_con (None, 4, 4, 256)    589824      discriminator_conv3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 256)    0           discriminatorres3_resblock0_conv1\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock0_con (None, 4, 4, 256)    589824      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 4, 256)    0           discriminator_conv3[0][0]        \n",
      "                                                                 discriminatorres3_resblock0_conv2\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock1_con (None, 4, 4, 256)    589824      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 4, 4, 256)    0           discriminatorres3_resblock1_conv1\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock1_con (None, 4, 4, 256)    589824      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 4, 256)    0           add_1[0][0]                      \n",
      "                                                                 discriminatorres3_resblock1_conv2\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock2_con (None, 4, 4, 256)    589824      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 256)    0           discriminatorres3_resblock2_conv1\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock2_con (None, 4, 4, 256)    589824      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 256)    0           add_2[0][0]                      \n",
      "                                                                 discriminatorres3_resblock2_conv2\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock3_con (None, 4, 4, 256)    589824      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 256)    0           discriminatorres3_resblock3_conv1\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock3_con (None, 4, 4, 256)    589824      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 256)    0           add_3[0][0]                      \n",
      "                                                                 discriminatorres3_resblock3_conv2\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock4_con (None, 4, 4, 256)    589824      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 4, 4, 256)    0           discriminatorres3_resblock4_conv1\n",
      "__________________________________________________________________________________________________\n",
      "discriminatorres3_resblock4_con (None, 4, 4, 256)    589824      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 256)    0           add_4[0][0]                      \n",
      "                                                                 discriminatorres3_resblock4_conv2\n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 4, 4, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_conv4 (Conv2D)    (None, 2, 2, 512)    2097152     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 2, 2, 512)    0           discriminator_conv4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "discriminator_conv5 (Conv2D)    (None, 2, 2, 1)      512         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4)            0           discriminator_conv5[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 8,654,336\n",
      "Trainable params: 8,654,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Generator Summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_dense (Dense)         (None, 8192)         1056768     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 4, 4, 512)    0           generator_dense[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 512)    0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "generator_conv1 (Conv2D)        (None, 8, 8, 256)    1179648     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "generator_bn1 (BatchNormalizati (None, 8, 8, 256)    1024        generator_conv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock0_conv1 ( (None, 8, 8, 256)    589824      generator_bn1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock0_bn1 (Ba (None, 8, 8, 256)    1024        generatorres1_resblock0_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 256)    0           generatorres1_resblock0_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock0_conv2 ( (None, 8, 8, 256)    589824      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock0_bn2 (Ba (None, 8, 8, 256)    1024        generatorres1_resblock0_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 256)    0           generator_bn1[0][0]              \n",
      "                                                                 generatorres1_resblock0_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock1_conv1 ( (None, 8, 8, 256)    589824      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock1_bn1 (Ba (None, 8, 8, 256)    1024        generatorres1_resblock1_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 256)    0           generatorres1_resblock1_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock1_conv2 ( (None, 8, 8, 256)    589824      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock1_bn2 (Ba (None, 8, 8, 256)    1024        generatorres1_resblock1_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 256)    0           add_6[0][0]                      \n",
      "                                                                 generatorres1_resblock1_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock2_conv1 ( (None, 8, 8, 256)    589824      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock2_bn1 (Ba (None, 8, 8, 256)    1024        generatorres1_resblock2_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 256)    0           generatorres1_resblock2_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock2_conv2 ( (None, 8, 8, 256)    589824      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres1_resblock2_bn2 (Ba (None, 8, 8, 256)    1024        generatorres1_resblock2_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           add_7[0][0]                      \n",
      "                                                                 generatorres1_resblock2_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 256)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generator_conv2 (Conv2D)        (None, 16, 16, 128)  294912      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "generator_bn2 (BatchNormalizati (None, 16, 16, 128)  512         generator_conv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock0_conv1 ( (None, 16, 16, 128)  147456      generator_bn2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock0_bn1 (Ba (None, 16, 16, 128)  512         generatorres2_resblock0_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 128)  0           generatorres2_resblock0_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock0_conv2 ( (None, 16, 16, 128)  147456      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock0_bn2 (Ba (None, 16, 16, 128)  512         generatorres2_resblock0_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 128)  0           generator_bn2[0][0]              \n",
      "                                                                 generatorres2_resblock0_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock1_conv1 ( (None, 16, 16, 128)  147456      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock1_bn1 (Ba (None, 16, 16, 128)  512         generatorres2_resblock1_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 128)  0           generatorres2_resblock1_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock1_conv2 ( (None, 16, 16, 128)  147456      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock1_bn2 (Ba (None, 16, 16, 128)  512         generatorres2_resblock1_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           add_9[0][0]                      \n",
      "                                                                 generatorres2_resblock1_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock2_conv1 ( (None, 16, 16, 128)  147456      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock2_bn1 (Ba (None, 16, 16, 128)  512         generatorres2_resblock2_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 128)  0           generatorres2_resblock2_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock2_conv2 ( (None, 16, 16, 128)  147456      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres2_resblock2_bn2 (Ba (None, 16, 16, 128)  512         generatorres2_resblock2_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           add_10[0][0]                     \n",
      "                                                                 generatorres2_resblock2_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 128)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generator_conv3 (Conv2D)        (None, 32, 32, 64)   73728       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "generator_bn3 (BatchNormalizati (None, 32, 32, 64)   256         generator_conv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock0_conv1 ( (None, 32, 32, 64)   36864       generator_bn3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock0_bn1 (Ba (None, 32, 32, 64)   256         generatorres3_resblock0_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           generatorres3_resblock0_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock0_conv2 ( (None, 32, 32, 64)   36864       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock0_bn2 (Ba (None, 32, 32, 64)   256         generatorres3_resblock0_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 64)   0           generator_bn3[0][0]              \n",
      "                                                                 generatorres3_resblock0_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock1_conv1 ( (None, 32, 32, 64)   36864       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock1_bn1 (Ba (None, 32, 32, 64)   256         generatorres3_resblock1_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 64)   0           generatorres3_resblock1_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock1_conv2 ( (None, 32, 32, 64)   36864       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock1_bn2 (Ba (None, 32, 32, 64)   256         generatorres3_resblock1_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 64)   0           add_12[0][0]                     \n",
      "                                                                 generatorres3_resblock1_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock2_conv1 ( (None, 32, 32, 64)   36864       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock2_bn1 (Ba (None, 32, 32, 64)   256         generatorres3_resblock2_conv1[0][\n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 64)   0           generatorres3_resblock2_bn1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock2_conv2 ( (None, 32, 32, 64)   36864       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "generatorres3_resblock2_bn2 (Ba (None, 32, 32, 64)   256         generatorres3_resblock2_conv2[0][\n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 64)   0           add_13[0][0]                     \n",
      "                                                                 generatorres3_resblock2_bn2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 64)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "generator_conv4 (Conv2D)        (None, 32, 32, 3)    1728        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 3)    0           generator_conv4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 7,264,192\n",
      "Trainable params: 7,257,920\n",
      "Non-trainable params: 6,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = DRAGAN(dataset, gpu_count, resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10001 [00:00<?, ?it/s]/home/k_yonhon/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "  0%|          | 1/10001 [00:13<37:07:30, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [C loss: nan] [G loss: nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/10001 [00:32<1:25:20,  1.95it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6c04d80b9c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-cdd8b48dfc3b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np_samples = gan.train(epochs=10000, batch_size=64, sample_interval=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gan.generator.save('./saved_model/dragan'+str(gan.λ)+'_gen_'+str(10000)+'epoch.h5')\n",
    "gan.critic.save('./saved_model/dragan'+str(gan.λ)+'_critic_'+str(10000)+'epoch.h5')\n",
    "np.savez_compressed('./saved_model/dragan'+str(gan.λ)+'_np_'+str(10000)+'epoch.npz', np_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.notebook_extension()\n",
    "for j in range(1, 11):\n",
    "    y = np_samples[j]\n",
    "    for i in range(5):\n",
    "        if j == 1 and i == 0:\n",
    "            hv_points = hv.RGB(y[i]).relabel(str(j*10000)+' epoch')\n",
    "        else:\n",
    "            hv_points += hv.RGB(y[i]).relabel(str(j*10000)+' epoch')\n",
    "hv_points.cols(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "noise = np.random.normal(0, 1, (50, gan.latent_dim))\n",
    "gen_imgs = gan.generator.predict(noise)\n",
    "y = ((0.5 * gen_imgs + 0.5) * 255).astype(np.uint8)\n",
    "for j in range(50):\n",
    "    if j == 0:\n",
    "        hv_points = hv.RGB(y[j])\n",
    "    else:\n",
    "        hv_points += hv.RGB(y[j])\n",
    "hv_points.cols(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Original\n",
    "gen_imgs = dataset / 127.5 - 1.0\n",
    "y = ((0.5 * gen_imgs + 0.5) * 255).astype(np.uint8)\n",
    "for j in range(50):\n",
    "    if j == 0:\n",
    "        hv_points = hv.RGB(y[j])\n",
    "    else:\n",
    "        hv_points += hv.RGB(y[j])\n",
    "hv_points.cols(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
