{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function, division"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.datasets import cifar10\n", "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n", "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n", "from keras.layers import MaxPooling2D\n", "from keras.layers.advanced_activations import LeakyReLU\n", "from keras.layers.convolutional import UpSampling2D, Conv2D\n", "from keras.models import Sequential, Model\n", "from keras.optimizers import Adam\n", "from keras import losses\n", "from keras.utils import to_categorical\n", "import keras.backend as K"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ContextEncoder():\n", "    def __init__(self):\n", "        self.img_rows = 32\n", "        self.img_cols = 32\n", "        self.mask_height = 8\n", "        self.mask_width = 8\n", "        self.channels = 3\n", "        self.num_classes = 2\n", "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n", "        self.missing_shape = (self.mask_height, self.mask_width, self.channels)\n", "        optimizer = Adam(0.0002, 0.5)\n\n", "        # Build and compile the discriminator\n", "        self.discriminator = self.build_discriminator()\n", "        self.discriminator.compile(loss='binary_crossentropy',\n", "            optimizer=optimizer,\n", "            metrics=['accuracy'])\n\n", "        # Build the generator\n", "        self.generator = self.build_generator()\n\n", "        # The generator takes noise as input and generates the missing\n", "        # part of the image\n", "        masked_img = Input(shape=self.img_shape)\n", "        gen_missing = self.generator(masked_img)\n\n", "        # For the combined model we will only train the generator\n", "        self.discriminator.trainable = False\n\n", "        # The discriminator takes generated images as input and determines\n", "        # if it is generated or if it is a real image\n", "        valid = self.discriminator(gen_missing)\n\n", "        # The combined model  (stacked generator and discriminator)\n", "        # Trains generator to fool discriminator\n", "        self.combined = Model(masked_img , [gen_missing, valid])\n", "        self.combined.compile(loss=['mse', 'binary_crossentropy'],\n", "            loss_weights=[0.999, 0.001],\n", "            optimizer=optimizer)\n", "    def build_generator(self):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        model = Sequential()\n\n", "        # Encoder\n", "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Conv2D(512, kernel_size=1, strides=2, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(Dropout(0.5))\n\n", "        # Decoder\n", "        model.add(UpSampling2D())\n", "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n", "        model.add(Activation('relu'))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(UpSampling2D())\n", "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n", "        model.add(Activation('relu'))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n", "        model.add(Activation('tanh'))\n", "        model.summary()\n", "        masked_img = Input(shape=self.img_shape)\n", "        gen_missing = model(masked_img)\n", "        return Model(masked_img, gen_missing)\n", "    def build_discriminator(self):\n", "        model = Sequential()\n", "        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.missing_shape, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n", "        model.add(LeakyReLU(alpha=0.2))\n", "        model.add(BatchNormalization(momentum=0.8))\n", "        model.add(Flatten())\n", "        model.add(Dense(1, activation='sigmoid'))\n", "        model.summary()\n", "        img = Input(shape=self.missing_shape)\n", "        validity = model(img)\n", "        return Model(img, validity)\n", "    def mask_randomly(self, imgs):\n", "        y1 = np.random.randint(0, self.img_rows - self.mask_height, imgs.shape[0])\n", "        y2 = y1 + self.mask_height\n", "        x1 = np.random.randint(0, self.img_rows - self.mask_width, imgs.shape[0])\n", "        x2 = x1 + self.mask_width\n", "        masked_imgs = np.empty_like(imgs)\n", "        missing_parts = np.empty((imgs.shape[0], self.mask_height, self.mask_width, self.channels))\n", "        for i, img in enumerate(imgs):\n", "            masked_img = img.copy()\n", "            _y1, _y2, _x1, _x2 = y1[i], y2[i], x1[i], x2[i]\n", "            missing_parts[i] = masked_img[_y1:_y2, _x1:_x2, :].copy()\n", "            masked_img[_y1:_y2, _x1:_x2, :] = 0\n", "            masked_imgs[i] = masked_img\n", "        return masked_imgs, missing_parts, (y1, y2, x1, x2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def train(self, epochs, batch_size=128, sample_interval=50):\n\n", "        # Load the dataset\n", "        (X_train, y_train), (_, _) = cifar10.load_data()\n\n", "        # Extract dogs and cats\n", "        X_cats = X_train[(y_train == 3).flatten()]\n", "        X_dogs = X_train[(y_train == 5).flatten()]\n", "        X_train = np.vstack((X_cats, X_dogs))\n\n", "        # Rescale -1 to 1\n", "        X_train = X_train / 127.5 - 1.\n", "        y_train = y_train.reshape(-1, 1)\n\n", "        # Adversarial ground truths\n", "        valid = np.ones((batch_size, 1))\n", "        fake = np.zeros((batch_size, 1))\n", "        for epoch in range(epochs):\n\n", "            # ---------------------\n", "            #  Train Discriminator\n", "            # ---------------------\n\n", "            # Select a random batch of images\n", "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n", "            imgs = X_train[idx]\n", "            masked_imgs, missing_parts, _ = self.mask_randomly(imgs)\n\n", "            # Generate a batch of new images\n", "            gen_missing = self.generator.predict(masked_imgs)\n\n", "            # Train the discriminator\n", "            d_loss_real = self.discriminator.train_on_batch(missing_parts, valid)\n", "            d_loss_fake = self.discriminator.train_on_batch(gen_missing, fake)\n", "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n", "            # ---------------------\n", "            #  Train Generator\n", "            # ---------------------\n", "            g_loss = self.combined.train_on_batch(masked_imgs, [missing_parts, valid])\n\n", "            # Plot the progress\n", "            print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], g_loss[1]))\n\n", "            # If at save interval => save generated image samples\n", "            if epoch % sample_interval == 0:\n", "                idx = np.random.randint(0, X_train.shape[0], 6)\n", "                imgs = X_train[idx]\n", "                self.sample_images(epoch, imgs)\n", "    def sample_images(self, epoch, imgs):\n", "        r, c = 3, 6\n", "        masked_imgs, missing_parts, (y1, y2, x1, x2) = self.mask_randomly(imgs)\n", "        gen_missing = self.generator.predict(masked_imgs)\n", "        imgs = 0.5 * imgs + 0.5\n", "        masked_imgs = 0.5 * masked_imgs + 0.5\n", "        gen_missing = 0.5 * gen_missing + 0.5\n", "        fig, axs = plt.subplots(r, c)\n", "        for i in range(c):\n", "            axs[0,i].imshow(imgs[i, :,:])\n", "            axs[0,i].axis('off')\n", "            axs[1,i].imshow(masked_imgs[i, :,:])\n", "            axs[1,i].axis('off')\n", "            filled_in = imgs[i].copy()\n", "            filled_in[y1[i]:y2[i], x1[i]:x2[i], :] = gen_missing[i]\n", "            axs[2,i].imshow(filled_in)\n", "            axs[2,i].axis('off')\n", "        fig.savefig(\"images/%d.png\" % epoch)\n", "        plt.close()\n", "    def save_model(self):\n", "        def save(model, model_name):\n", "            model_path = \"saved_model/%s.json\" % model_name\n", "            weights_path = \"saved_model/%s_weights.hdf5\" % model_name\n", "            options = {\"file_arch\": model_path,\n", "                        \"file_weight\": weights_path}\n", "            json_string = model.to_json()\n", "            open(options['file_arch'], 'w').write(json_string)\n", "            model.save_weights(options['file_weight'])\n", "        save(self.generator, \"generator\")\n", "        save(self.discriminator, \"discriminator\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    context_encoder = ContextEncoder()\n", "    context_encoder.train(epochs=30000, batch_size=64, sample_interval=50)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}