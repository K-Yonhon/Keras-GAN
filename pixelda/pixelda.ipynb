{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function, division\n", "import scipy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.datasets import mnist\n", "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n", "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n", "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n", "from keras.layers.advanced_activations import LeakyReLU\n", "from keras.layers.convolutional import UpSampling2D, Conv2D\n", "from keras.models import Sequential, Model\n", "from keras.optimizers import Adam\n", "from keras.utils import to_categorical\n", "import datetime\n", "import matplotlib.pyplot as plt\n", "import sys\n", "from data_loader import DataLoader\n", "import numpy as np\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class PixelDA():\n", "    def __init__(self):\n", "        # Input shape\n", "        self.img_rows = 32\n", "        self.img_cols = 32\n", "        self.channels = 3\n", "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n", "        self.num_classes = 10\n\n", "        # Configure MNIST and MNIST-M data loader\n", "        self.data_loader = DataLoader(img_res=(self.img_rows, self.img_cols))\n\n", "        # Loss weights\n", "        lambda_adv = 10\n", "        lambda_clf = 1\n\n", "        # Calculate output shape of D (PatchGAN)\n", "        patch = int(self.img_rows / 2**4)\n", "        self.disc_patch = (patch, patch, 1)\n\n", "        # Number of residual blocks in the generator\n", "        self.residual_blocks = 6\n", "        optimizer = Adam(0.0002, 0.5)\n\n", "        # Number of filters in first layer of discriminator and classifier\n", "        self.df = 64\n", "        self.cf = 64\n\n", "        # Build and compile the discriminators\n", "        self.discriminator = self.build_discriminator()\n", "        self.discriminator.compile(loss='mse',\n", "            optimizer=optimizer,\n", "            metrics=['accuracy'])\n\n", "        # Build the generator\n", "        self.generator = self.build_generator()\n\n", "        # Build the task (classification) network\n", "        self.clf = self.build_classifier()\n\n", "        # Input images from both domains\n", "        img_A = Input(shape=self.img_shape)\n", "        img_B = Input(shape=self.img_shape)\n\n", "        # Translate images from domain A to domain B\n", "        fake_B = self.generator(img_A)\n\n", "        # Classify the translated image\n", "        class_pred = self.clf(fake_B)\n\n", "        # For the combined model we will only train the generator and classifier\n", "        self.discriminator.trainable = False\n\n", "        # Discriminator determines validity of translated images\n", "        valid = self.discriminator(fake_B)\n", "        self.combined = Model(img_A, [valid, class_pred])\n", "        self.combined.compile(loss=['mse', 'categorical_crossentropy'],\n", "                                    loss_weights=[lambda_adv, lambda_clf],\n", "                                    optimizer=optimizer,\n", "                                    metrics=['accuracy'])\n", "    def build_generator(self):\n", "        \"\"\"Resnet Generator\"\"\"\n", "        def residual_block(layer_input):\n", "            \"\"\"Residual block described in paper\"\"\"\n", "            d = Conv2D(64, kernel_size=3, strides=1, padding='same')(layer_input)\n", "            d = BatchNormalization(momentum=0.8)(d)\n", "            d = Activation('relu')(d)\n", "            d = Conv2D(64, kernel_size=3, strides=1, padding='same')(d)\n", "            d = BatchNormalization(momentum=0.8)(d)\n", "            d = Add()([d, layer_input])\n", "            return d\n\n", "        # Image input\n", "        img = Input(shape=self.img_shape)\n", "        l1 = Conv2D(64, kernel_size=3, padding='same', activation='relu')(img)\n\n", "        # Propogate signal through residual blocks\n", "        r = residual_block(l1)\n", "        for _ in range(self.residual_blocks - 1):\n", "            r = residual_block(r)\n", "        output_img = Conv2D(self.channels, kernel_size=3, padding='same', activation='tanh')(r)\n", "        return Model(img, output_img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def build_discriminator(self):\n", "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n", "            \"\"\"Discriminator layer\"\"\"\n", "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n", "            d = LeakyReLU(alpha=0.2)(d)\n", "            if normalization:\n", "                d = InstanceNormalization()(d)\n", "            return d\n", "        img = Input(shape=self.img_shape)\n", "        d1 = d_layer(img, self.df, normalization=False)\n", "        d2 = d_layer(d1, self.df*2)\n", "        d3 = d_layer(d2, self.df*4)\n", "        d4 = d_layer(d3, self.df*8)\n", "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n", "        return Model(img, validity)\n", "    def build_classifier(self):\n", "        def clf_layer(layer_input, filters, f_size=4, normalization=True):\n", "            \"\"\"Classifier layer\"\"\"\n", "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n", "            d = LeakyReLU(alpha=0.2)(d)\n", "            if normalization:\n", "                d = InstanceNormalization()(d)\n", "            return d\n", "        img = Input(shape=self.img_shape)\n", "        c1 = clf_layer(img, self.cf, normalization=False)\n", "        c2 = clf_layer(c1, self.cf*2)\n", "        c3 = clf_layer(c2, self.cf*4)\n", "        c4 = clf_layer(c3, self.cf*8)\n", "        c5 = clf_layer(c4, self.cf*8)\n", "        class_pred = Dense(self.num_classes, activation='softmax')(Flatten()(c5))\n", "        return Model(img, class_pred)\n", "    def train(self, epochs, batch_size=128, sample_interval=50):\n", "        half_batch = int(batch_size / 2)\n\n", "        # Classification accuracy on 100 last batches of domain B\n", "        test_accs = []\n\n", "        # Adversarial ground truths\n", "        valid = np.ones((batch_size, *self.disc_patch))\n", "        fake = np.zeros((batch_size, *self.disc_patch))\n", "        for epoch in range(epochs):\n\n", "            # ---------------------\n", "            #  Train Discriminator\n", "            # ---------------------\n", "            imgs_A, labels_A = self.data_loader.load_data(domain=\"A\", batch_size=batch_size)\n", "            imgs_B, labels_B = self.data_loader.load_data(domain=\"B\", batch_size=batch_size)\n\n", "            # Translate images from domain A to domain B\n", "            fake_B = self.generator.predict(imgs_A)\n\n", "            # Train the discriminators (original images = real / translated = Fake)\n", "            d_loss_real = self.discriminator.train_on_batch(imgs_B, valid)\n", "            d_loss_fake = self.discriminator.train_on_batch(fake_B, fake)\n", "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # --------------------------------\n", "            #  Train Generator and Classifier\n", "            # --------------------------------\n\n", "            # One-hot encoding of labels\n", "            labels_A = to_categorical(labels_A, num_classes=self.num_classes)\n\n", "            # Train the generator and classifier\n", "            g_loss = self.combined.train_on_batch(imgs_A, [valid, labels_A])\n\n", "            #-----------------------\n", "            # Evaluation (domain B)\n", "            #-----------------------\n", "            pred_B = self.clf.predict(imgs_B)\n", "            test_acc = np.mean(np.argmax(pred_B, axis=1) == labels_B)\n\n", "            # Add accuracy to list of last 100 accuracy measurements\n", "            test_accs.append(test_acc)\n", "            if len(test_accs) > 100:\n", "                test_accs.pop(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # Plot the progress\n", "            print ( \"%d : [D - loss: %.5f, acc: %3d%%], [G - loss: %.5f], [clf - loss: %.5f, acc: %3d%%, test_acc: %3d%% (%3d%%)]\" % \\\n", "                                            (epoch, d_loss[0], 100*float(d_loss[1]),\n", "                                            g_loss[1], g_loss[2], 100*float(g_loss[-1]),\n", "                                            100*float(test_acc), 100*float(np.mean(test_accs))))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # If at save interval => save generated image samples\n", "            if epoch % sample_interval == 0:\n", "                self.sample_images(epoch)\n", "    def sample_images(self, epoch):\n", "        r, c = 2, 5\n", "        imgs_A, _ = self.data_loader.load_data(domain=\"A\", batch_size=5)\n\n", "        # Translate images to the other domain\n", "        fake_B = self.generator.predict(imgs_A)\n", "        gen_imgs = np.concatenate([imgs_A, fake_B])\n\n", "        # Rescale images 0 - 1\n", "        gen_imgs = 0.5 * gen_imgs + 0.5\n\n", "        #titles = ['Original', 'Translated']\n", "        fig, axs = plt.subplots(r, c)\n", "        cnt = 0\n", "        for i in range(r):\n", "            for j in range(c):\n", "                axs[i,j].imshow(gen_imgs[cnt])\n", "                #axs[i, j].set_title(titles[i])\n", "                axs[i,j].axis('off')\n", "                cnt += 1\n", "        fig.savefig(\"images/%d.png\" % (epoch))\n", "        plt.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    gan = PixelDA()\n", "    gan.train(epochs=30000, batch_size=32, sample_interval=500)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}