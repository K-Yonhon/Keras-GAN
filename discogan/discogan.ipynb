{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function, division\n", "import scipy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.datasets import mnist\n", "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n", "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n", "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n", "from keras.layers.advanced_activations import LeakyReLU\n", "from keras.layers.convolutional import UpSampling2D, Conv2D\n", "from keras.models import Sequential, Model\n", "from keras.optimizers import Adam\n", "import datetime\n", "import matplotlib.pyplot as plt\n", "import sys\n", "from data_loader import DataLoader\n", "import numpy as np\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DiscoGAN():\n", "    def __init__(self):\n", "        # Input shape\n", "        self.img_rows = 128\n", "        self.img_cols = 128\n", "        self.channels = 3\n", "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n", "        # Configure data loader\n", "        self.dataset_name = 'edges2shoes'\n", "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n", "                                      img_res=(self.img_rows, self.img_cols))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # Calculate output shape of D (PatchGAN)\n", "        patch = int(self.img_rows / 2**4)\n", "        self.disc_patch = (patch, patch, 1)\n\n", "        # Number of filters in the first layer of G and D\n", "        self.gf = 64\n", "        self.df = 64\n", "        optimizer = Adam(0.0002, 0.5)\n\n", "        # Build and compile the discriminators\n", "        self.d_A = self.build_discriminator()\n", "        self.d_B = self.build_discriminator()\n", "        self.d_A.compile(loss='mse',\n", "            optimizer=optimizer,\n", "            metrics=['accuracy'])\n", "        self.d_B.compile(loss='mse',\n", "            optimizer=optimizer,\n", "            metrics=['accuracy'])\n\n", "        #-------------------------\n", "        # Construct Computational\n", "        #   Graph of Generators\n", "        #-------------------------\n\n", "        # Build the generators\n", "        self.g_AB = self.build_generator()\n", "        self.g_BA = self.build_generator()\n\n", "        # Input images from both domains\n", "        img_A = Input(shape=self.img_shape)\n", "        img_B = Input(shape=self.img_shape)\n\n", "        # Translate images to the other domain\n", "        fake_B = self.g_AB(img_A)\n", "        fake_A = self.g_BA(img_B)\n", "        # Translate images back to original domain\n", "        reconstr_A = self.g_BA(fake_B)\n", "        reconstr_B = self.g_AB(fake_A)\n\n", "        # For the combined model we will only train the generators\n", "        self.d_A.trainable = False\n", "        self.d_B.trainable = False\n\n", "        # Discriminators determines validity of translated images\n", "        valid_A = self.d_A(fake_A)\n", "        valid_B = self.d_B(fake_B)\n\n", "        # Objectives\n", "        # + Adversarial: Fool domain discriminators\n", "        # + Translation: Minimize MAE between e.g. fake B and true B\n", "        # + Cycle-consistency: Minimize MAE between reconstructed images and original\n", "        self.combined = Model(inputs=[img_A, img_B],\n", "                              outputs=[ valid_A, valid_B,\n", "                                        fake_B, fake_A,\n", "                                        reconstr_A, reconstr_B ])\n", "        self.combined.compile(loss=['mse', 'mse',\n", "                                    'mae', 'mae',\n", "                                    'mae', 'mae'],\n", "                              optimizer=optimizer)\n", "    def build_generator(self):\n", "        \"\"\"U-Net Generator\"\"\"\n", "        def conv2d(layer_input, filters, f_size=4, normalize=True):\n", "            \"\"\"Layers used during downsampling\"\"\"\n", "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n", "            d = LeakyReLU(alpha=0.2)(d)\n", "            if normalize:\n", "                d = InstanceNormalization()(d)\n", "            return d\n", "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n", "            \"\"\"Layers used during upsampling\"\"\"\n", "            u = UpSampling2D(size=2)(layer_input)\n", "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n", "            if dropout_rate:\n", "                u = Dropout(dropout_rate)(u)\n", "            u = InstanceNormalization()(u)\n", "            u = Concatenate()([u, skip_input])\n", "            return u\n\n", "        # Image input\n", "        d0 = Input(shape=self.img_shape)\n\n", "        # Downsampling\n", "        d1 = conv2d(d0, self.gf, normalize=False)\n", "        d2 = conv2d(d1, self.gf*2)\n", "        d3 = conv2d(d2, self.gf*4)\n", "        d4 = conv2d(d3, self.gf*8)\n", "        d5 = conv2d(d4, self.gf*8)\n", "        d6 = conv2d(d5, self.gf*8)\n", "        d7 = conv2d(d6, self.gf*8)\n\n", "        # Upsampling\n", "        u1 = deconv2d(d7, d6, self.gf*8)\n", "        u2 = deconv2d(u1, d5, self.gf*8)\n", "        u3 = deconv2d(u2, d4, self.gf*8)\n", "        u4 = deconv2d(u3, d3, self.gf*4)\n", "        u5 = deconv2d(u4, d2, self.gf*2)\n", "        u6 = deconv2d(u5, d1, self.gf)\n", "        u7 = UpSampling2D(size=2)(u6)\n", "        output_img = Conv2D(self.channels, kernel_size=4, strides=1,\n", "                            padding='same', activation='tanh')(u7)\n", "        return Model(d0, output_img)\n", "    def build_discriminator(self):\n", "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n", "            \"\"\"Discriminator layer\"\"\"\n", "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n", "            d = LeakyReLU(alpha=0.2)(d)\n", "            if normalization:\n", "                d = InstanceNormalization()(d)\n", "            return d\n", "        img = Input(shape=self.img_shape)\n", "        d1 = d_layer(img, self.df, normalization=False)\n", "        d2 = d_layer(d1, self.df*2)\n", "        d3 = d_layer(d2, self.df*4)\n", "        d4 = d_layer(d3, self.df*8)\n", "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n", "        return Model(img, validity)\n", "    def train(self, epochs, batch_size=128, sample_interval=50):\n", "        start_time = datetime.datetime.now()\n\n", "        # Adversarial loss ground truths\n", "        valid = np.ones((batch_size,) + self.disc_patch)\n", "        fake = np.zeros((batch_size,) + self.disc_patch)\n", "        for epoch in range(epochs):\n", "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n", "                # ----------------------\n", "                #  Train Discriminators\n", "                # ----------------------\n", "                # Translate images to opposite domain\n", "                fake_B = self.g_AB.predict(imgs_A)\n", "                fake_A = self.g_BA.predict(imgs_B)\n", "                # Train the discriminators (original images = real / translated = Fake)\n", "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n", "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n", "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n", "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n", "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n", "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n", "                # Total disciminator loss\n", "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n", "                # ------------------\n", "                #  Train Generators\n", "                # ------------------\n", "                # Train the generators\n", "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, \\\n", "                                                                         imgs_B, imgs_A, \\\n", "                                                                         imgs_A, imgs_B])\n", "                elapsed_time = datetime.datetime.now() - start_time\n", "                # Plot the progress\n", "                print (\"[%d] [%d/%d] time: %s, [d_loss: %f, g_loss: %f]\" % (epoch, batch_i,\n", "                                                                        self.data_loader.n_batches,\n", "                                                                        elapsed_time,\n", "                                                                        d_loss[0], g_loss[0]))\n", "                # If at save interval => save generated image samples\n", "                if batch_i % sample_interval == 0:\n", "                    self.sample_images(epoch, batch_i)\n", "    def sample_images(self, epoch, batch_i):\n", "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n", "        r, c = 2, 3\n", "        imgs_A, imgs_B = self.data_loader.load_data(batch_size=1, is_testing=True)\n\n", "        # Translate images to the other domain\n", "        fake_B = self.g_AB.predict(imgs_A)\n", "        fake_A = self.g_BA.predict(imgs_B)\n", "        # Translate back to original domain\n", "        reconstr_A = self.g_BA.predict(fake_B)\n", "        reconstr_B = self.g_AB.predict(fake_A)\n", "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n\n", "        # Rescale images 0 - 1\n", "        gen_imgs = 0.5 * gen_imgs + 0.5\n", "        titles = ['Original', 'Translated', 'Reconstructed']\n", "        fig, axs = plt.subplots(r, c)\n", "        cnt = 0\n", "        for i in range(r):\n", "            for j in range(c):\n", "                axs[i,j].imshow(gen_imgs[cnt])\n", "                axs[i, j].set_title(titles[j])\n", "                axs[i,j].axis('off')\n", "                cnt += 1\n", "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n", "        plt.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    gan = DiscoGAN()\n", "    gan.train(epochs=20, batch_size=1, sample_interval=200)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}