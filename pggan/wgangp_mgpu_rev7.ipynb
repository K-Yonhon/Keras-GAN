{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2h over -> 40min by Multi GPU!\n",
    "\n",
    "TASK\n",
    "d_loss　これまでと比較できるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Reshape, Flatten, Activation\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "import shutil, os, sys, io, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from functools import partial\n",
    "from itertools import zip_longest\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('/home/k_yonhon/py/Keras-GAN/pggan/')\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from tensor_board_logger import TensorBoardLogger\n",
    "from layer_visualizer import LayerVisualizer\n",
    "\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "\n",
    "gpu_count = 2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Takes a randomly-weighted average of two tensors. In geometric terms, this\n",
    "    outputs a random point on the line between each pair of input points.\n",
    "    Inheriting from _Merge is a little messy but it was the quickest solution I could\n",
    "    think of. Improvements appreciated.\"\"\"\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        weights = K.random_uniform((batch_size, 1, 1, 1))\n",
    "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])\n",
    "\n",
    "def compute_gradients(tensor, var_list):\n",
    "    grads = tf.gradients(tensor, var_list) # return A list of sum(dy/dx) for each x in xs.\n",
    "    return [grad if grad is not None else tf.zeros_like(var) for grad, var in zip_longest(grads, var_list)]\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples,\n",
    "                          gradient_penalty_weight):\n",
    "    # gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients = compute_gradients(y_pred, [averaged_samples])[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        # ---------------------\n",
    "        #  for log on TensorBoard\n",
    "        # ---------------------\n",
    "        target_dir = \"./my_log_dir\"\n",
    "        shutil.rmtree(target_dir, ignore_errors=True)\n",
    "        os.mkdir(target_dir)\n",
    "        self.logger = TensorBoardLogger(log_dir=target_dir)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Parameter\n",
    "        # ---------------------\n",
    "        self.resume = 0\n",
    "        \n",
    "        self.n_critic = 5\n",
    "        self.λ = 10\n",
    "        \n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.input_rows = 4\n",
    "        self.input_cols = 4\n",
    "        self.latent_dim = 128  # Noiseの次元\n",
    "        optimizer = Adam(lr=0.00001, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        # optimizer = Adam(lr=0.00005, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        # optimizer = Adam(0.0001, beta_1=0., beta_2=0.9)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Build model\n",
    "        # ---------------------\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            if self.resume == 0:\n",
    "                self.critic = self.build_critic()\n",
    "                self.generator = self.build_generator()\n",
    "            else:\n",
    "                self.critic = load_model('./saved_model/wgangp32_disc_model_'+str(self.resume)+'epoch.h5')\n",
    "                self.generator = load_model('./saved_model/wgangp32_gen_model_'+str(self.resume)+'epoch.h5')\n",
    "                \n",
    "            #  Load pretrained weights\n",
    "            pre_gen = load_model('./saved_model/wgangp16_gen_model.h5')\n",
    "            for i, layer in enumerate(self.generator.layers[1].layers):\n",
    "                if i in [i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]:\n",
    "                    layer.set_weights(pre_gen.layers[1].layers[i].get_weights())\n",
    "\n",
    "            pre_critic = load_model('./saved_model/wgangp16_disc_model.h5')\n",
    "            for i, layer in enumerate(self.critic.layers[1].layers):\n",
    "                j = i - len(self.critic.layers[1].layers)\n",
    "                if j in [-i for i in range(int(math.log(self.img_rows / self.input_rows, 2)) * 2, 0, -2)]:\n",
    "                    layer.set_weights(pre_critic.layers[1].layers[j].get_weights())\n",
    "                    layer.trainable = False\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "     \n",
    "        real_samples = Input(shape=self.img_shape)\n",
    "        generator_input_for_discriminator = Input(shape=(self.latent_dim,))\n",
    "        generated_samples_for_discriminator = self.generator(generator_input_for_discriminator)\n",
    "        discriminator_output_from_generator = self.critic(generated_samples_for_discriminator)\n",
    "        discriminator_output_from_real_samples = self.critic(real_samples)\n",
    "\n",
    "        averaged_samples = RandomWeightedAverage()([real_samples,\n",
    "                                                    generated_samples_for_discriminator])\n",
    "        averaged_samples_out = self.critic(averaged_samples)\n",
    "\n",
    "        partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                                  averaged_samples=averaged_samples,\n",
    "                                  gradient_penalty_weight=self.λ)\n",
    "        # Functions need names or Keras will throw an error\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_samples, \n",
    "                                          generator_input_for_discriminator],\n",
    "                                  outputs=[discriminator_output_from_real_samples, \n",
    "                                           discriminator_output_from_generator,\n",
    "                                           averaged_samples_out])\n",
    "        if gpu_count > 1:\n",
    "            self.critic_model = multi_gpu_model(self.critic_model, gpus=gpu_count)\n",
    "        self.critic_model.compile(optimizer=optimizer, \n",
    "                                  loss=[wasserstein_loss, \n",
    "                                        wasserstein_loss, \n",
    "                                        partial_gp_loss])\n",
    "        \n",
    "        print('Critic Summary:')\n",
    "        self.critic.summary()       \n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "        for i, layer in enumerate(self.generator.layers[1].layers):\n",
    "            if i in [i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]:\n",
    "                layer.trainable = False\n",
    "                    \n",
    "        generator_input = Input(shape=(self.latent_dim,))\n",
    "        generator_layers = self.generator(generator_input)\n",
    "        discriminator_layers_for_generator = self.critic(generator_layers)\n",
    "        \n",
    "        self.generator_model = Model(inputs=[generator_input], \n",
    "                                     outputs=[discriminator_layers_for_generator])\n",
    "        if gpu_count > 1:\n",
    "            self.generator_model = multi_gpu_model(self.generator_model, gpus=gpu_count)\n",
    "        self.generator_model.compile(optimizer=optimizer,\n",
    "                                     loss=wasserstein_loss)        \n",
    "\n",
    "        print('Genarator Summary:')\n",
    "        self.generator.summary()\n",
    "   \n",
    "    def build_generator(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            model = Sequential()\n",
    "            model.add(Reshape((self.input_rows, self.input_cols, int(self.latent_dim / (self.input_rows * self.input_cols))), \n",
    "                              input_shape=(self.latent_dim,)\n",
    "                             ))\n",
    "\n",
    "            model.add(Conv2DTranspose(512, (3, 3), strides=1, padding='same',\n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))      \n",
    "\n",
    "            for _ in range(int(math.log(self.img_rows / self.input_rows, 2))):\n",
    "                model.add(Conv2DTranspose(512, (3, 3), strides=2, padding='same', \n",
    "                                         kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                         ))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(256, (3, 3), strides=1, padding='same', \n",
    "                                      kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                      ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(128, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(64, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(32, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(16, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(3, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))                \n",
    "            model.add(Activation(\"tanh\"))\n",
    "\n",
    "            noise = Input(shape=(self.latent_dim,))\n",
    "            img = model(noise)\n",
    "            return Model(noise, img)\n",
    "    \n",
    "    def build_critic(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(16, (1, 1), strides=1, input_shape=self.img_shape, padding=\"valid\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(32, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(64, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(128, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(256, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(512, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            for _ in range(int(math.log(self.img_rows / self.input_rows, 2))):\n",
    "                model.add(Conv2D(512, (3, 3), strides=2, padding=\"same\",\n",
    "                                 kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                ))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(1, (4, 4), strides=1, padding=\"valid\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(Flatten())\n",
    "\n",
    "            img = Input(shape=self.img_shape)\n",
    "            validity = model(img)\n",
    "            return Model(img, validity)\n",
    "    \n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "        # ---------------------\n",
    "        #  Load the dataset\n",
    "        # ---------------------      \n",
    "        # Original dataset\n",
    "        X_train = np.load('../datasets/lfw32.npz')['arr_0']\n",
    "        X_train = X_train / 127.5 - 1.0   # Rescale -1 to 1\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1), dtype=np.float32)\n",
    "        fake = -np.ones((batch_size, 1), dtype=np.float32)\n",
    "        dummy = np.zeros((batch_size, 1), dtype=np.float32)\n",
    "        \n",
    "        for epoch in tqdm(range(self.resume, self.resume + epochs + 1)):\n",
    "            for _ in range(self.n_critic):\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                # Train the critic\n",
    "                d_loss = self.critic_model.train_on_batch([imgs, noise], \n",
    "                                                          [valid, fake, dummy])\n",
    "                d_loss = d_loss[0]\n",
    "                \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Log on TensorBoard\n",
    "            # ---------------------\n",
    "            # Backup Model\n",
    "            # if epoch != 0 and epoch % 1000 == 0:\n",
    "            #     self.critic.save('./saved_model/wgangp32_disc_model_'+str(epoch+self.resume)+'epoch.h5')\n",
    "            #     self.generator.save('./saved_model/wgangp32_gen_model_'+str(epoch+self.resume)+'epoch.h5')\n",
    "            \n",
    "            # Save Loss & Histgram\n",
    "            logs = {\n",
    "                \"Discriminator/loss\": d_loss,\n",
    "                \"Generator/loss\": g_loss,\n",
    "            }\n",
    "\n",
    "            histograms = {}\n",
    "            for layer in self.critic.layers[1].layers:\n",
    "                for i in range(len(layer.get_weights())):\n",
    "                    if \"conv\" in layer.name or \"dense\" in layer.name:\n",
    "                        name = layer.name + \"/\" + str(i)\n",
    "                        value = layer.get_weights()[i]\n",
    "                        histograms[name] = value\n",
    "            self.logger.log(logs=logs, histograms=histograms, epoch=epoch+self.resume)\n",
    "            \n",
    "            # Save generated image samples\n",
    "            if epoch+self.resume == 1000 or epoch+self.resume == 2000 or (epoch+self.resume) % sample_interval == 0:\n",
    "                fig, name = self.sample_images(epoch+self.resume)\n",
    "                images = {name: fig}\n",
    "                self.logger.log(images=images, epoch=epoch+self.resume)\n",
    "                print(\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss, g_loss))\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = ((0.5 * gen_imgs + 0.5) * 255).astype(np.uint8)\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                if self.channels == 1:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap=\"gray\")\n",
    "                else:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, :self.channels], cmap=\"gray\")\n",
    "                axs[i, j].axis(\"off\")\n",
    "                cnt += 1\n",
    "        name = str(epoch) + \".png\"\n",
    "        return fig, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k_yonhon/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic Summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 8660001   \n",
      "=================================================================\n",
      "Total params: 8,660,001\n",
      "Trainable params: 3,932,192\n",
      "Non-trainable params: 4,727,809\n",
      "_________________________________________________________________\n",
      "Genarator Summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 32, 32, 3)         8689059   \n",
      "=================================================================\n",
      "Total params: 8,689,059\n",
      "Trainable params: 3,932,067\n",
      "Non-trainable params: 4,756,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wgan = WGANGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../datasets/lfw32.npz')['arr_0']\n",
    "X_train = X_train / 127.5 - 1.0   # Rescale -1 to 1\n",
    "idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "real_samples = X_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input_for_discriminator = np.random.normal(0, 1, (batch_size, 128))\n",
    "generated_samples_for_discriminator = wgan.generator.predict(generator_input_for_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer random_weighted_average_3 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[[ 0.34901961,  0.00392157, -0.30196078],\n         [ 0.5372549 ,  0.12156863, -0.22352941],\n         [ 0.64705882,  0.19215686, -0.12156863],\n         ...,\n         [-0.30980392, -0.58431373, -0.83529412],\n         [-0.3254902 , -0.6       , -0.81960784],\n         [-0.2       , -0.48235294, -0.73333333]],\n\n        [[-0.00392157, -0.28627451, -0.5372549 ],\n         [-0.30980392, -0.6       , -0.81176471],\n         [ 0.23137255, -0.1372549 , -0.37254902],\n         ...,\n         [-0.3254902 , -0.58431373, -0.84313725],\n         [-0.34901961, -0.61568627, -0.83529412],\n         [-0.17647059, -0.48235294, -0.7254902 ]],\n\n        [[-0.16862745, -0.4745098 , -0.71764706],\n         [-0.60784314, -0.82745098, -0.92156863],\n         [-0.34901961, -0.63921569, -0.78039216],\n         ...,\n         [-0.3254902 , -0.59215686, -0.81176471],\n         [-0.35686275, -0.6       , -0.82745098],\n         [-0.16078431, -0.48235294, -0.71764706]],\n\n        ...,\n\n        [[-0.41176471, -0.48235294, -0.5372549 ],\n         [-0.41176471, -0.55294118, -0.6627451 ],\n         [-0.34117647, -0.41960784, -0.41176471],\n         ...,\n         [ 0.10588235, -0.18431373, -0.39607843],\n         [ 0.1372549 , -0.14509804, -0.31764706],\n         [ 0.15294118, -0.09803922, -0.21568627]],\n\n        [[-0.90588235, -0.98431373, -1.        ],\n         [-0.56862745, -0.63137255, -0.54509804],\n         [-0.78823529, -0.71764706, -0.4745098 ],\n         ...,\n         [ 0.0745098 , -0.2       , -0.35686275],\n         [ 0.19215686, -0.12941176, -0.27058824],\n         [ 0.12941176, -0.12156863, -0.22352941]],\n\n        [[-0.34901961, -0.43529412, -0.40392157],\n         [-0.91372549, -0.89019608, -0.77254902],\n         [-0.95294118, -0.89803922, -0.75686275],\n         ...,\n         [ 0.0745098 , -0.17647059, -0.37254902],\n         [-0.04313725, -0.23921569, -0.27843137],\n         [-0.04313725, -0.24705882, -0.25490196]]],\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ],\n         [-0.36470588, -0.49803922, -0.70196078],\n         ...,\n         [-0.0745098 , -0.00392157, -0.16862745],\n         [-0.0745098 , -0.00392157, -0.16862745],\n         [-0.09019608, -0.01960784, -0.18431373]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ],\n         [-0.38039216, -0.51372549, -0.71764706],\n         ...,\n         [-0.06666667,  0.00392157, -0.16078431],\n         [-0.06666667,  0.00392157, -0.16078431],\n         [-0.08235294, -0.01176471, -0.17647059]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-0.97647059, -1.        , -1.        ],\n         [-0.38039216, -0.51372549, -0.71764706],\n         ...,\n         [-0.06666667,  0.00392157, -0.16078431],\n         [-0.05882353,  0.01176471, -0.15294118],\n         [-0.06666667,  0.00392157, -0.16078431]],\n\n        ...,\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -0.98431373],\n         [-0.78823529, -0.79607843, -0.75686275],\n         ...,\n         [ 0.22352941, -0.12156863, -0.14509804],\n         [ 0.08235294, -0.14509804, -0.20784314],\n         [-0.67843137, -0.70196078, -0.74117647]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -0.98431373],\n         [-0.78823529, -0.79607843, -0.75686275],\n         ...,\n         [ 0.34901961,  0.2       ,  0.09019608],\n         [-0.48235294, -0.5372549 , -0.61568627],\n         [-0.74901961, -0.73333333, -0.75686275]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-0.99215686, -0.99215686, -0.97647059],\n         [-0.80392157, -0.81176471, -0.77254902],\n         ...,\n         [ 0.05882353, -0.00392157, -0.09019608],\n         [-0.85882353, -0.85882353, -0.8745098 ],\n         [-0.8745098 , -0.8745098 , -0.8745098 ]]],\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[ 0.51372549,  0.55294118,  0.37254902],\n         [ 0.57647059,  0.61568627,  0.45882353],\n         [ 0.63921569,  0.67843137,  0.50588235],\n         ...,\n         [ 0.80392157,  0.85882353,  0.73333333],\n         [ 0.78039216,  0.83529412,  0.70980392],\n         [ 0.77254902,  0.82745098,  0.70196078]],\n\n        ...,\n\n        [[ 0.58431373,  0.19215686,  0.2       ],\n         [ 0.67058824,  0.63921569,  0.44313725],\n         [-0.63137255, -0.62352941, -0.68627451],\n         ...,\n         [-0.74901961, -0.78039216, -0.80392157],\n         [-0.75686275, -0.78039216, -0.81960784],\n         [-0.74901961, -0.77254902, -0.81176471]],\n\n        [[ 0.00392157, -0.50588235, -0.5372549 ],\n         [ 0.31764706, -0.05882353, -0.1372549 ],\n         [-0.70196078, -0.73333333, -0.75686275],\n         ...,\n         [-0.77254902, -0.76470588, -0.80392157],\n         [-0.79607843, -0.79607843, -0.81176471],\n         [-0.80392157, -0.80392157, -0.81960784]],\n\n        [[-0.14509804, -0.59215686, -0.6627451 ],\n         [-0.40392157, -0.42745098, -0.49803922],\n         [-0.78039216, -0.77254902, -0.81960784],\n         ...,\n         [-0.81176471, -0.79607843, -0.81960784],\n         [-0.80392157, -0.78823529, -0.79607843],\n         [-0.78823529, -0.78039216, -0.76470588]]],\n\n\n       ...,\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-0.98431373, -1.        , -0.97647059],\n         [-0.98431373, -1.        , -0.97647059],\n         [-0.97647059, -1.        , -0.98431373],\n         ...,\n         [-0.96862745, -1.        , -1.        ],\n         [-0.95294118, -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ]],\n\n        ...,\n\n        [[-0.49803922, -0.45098039, -0.46666667],\n         [-0.52941176, -0.48235294, -0.49803922],\n         [-0.27058824, -0.27058824, -0.34901961],\n         ...,\n         [ 0.86666667,  0.4745098 ,  0.2       ],\n         [ 0.98431373,  0.62352941,  0.44313725],\n         [ 0.70980392,  0.18431373,  0.23921569]],\n\n        [[-0.38039216, -0.34901961, -0.3254902 ],\n         [-0.34901961, -0.35686275, -0.39607843],\n         [ 0.54509804,  0.35686275,  0.15294118],\n         ...,\n         [ 0.96078431,  0.52156863,  0.24705882],\n         [ 0.92941176,  0.58431373,  0.37254902],\n         [ 0.99215686,  0.70196078,  0.56078431]],\n\n        [[-0.2627451 , -0.27843137, -0.37254902],\n         [ 0.51372549,  0.28627451,  0.01960784],\n         [ 0.52941176,  0.12941176, -0.22352941],\n         ...,\n         [ 0.49019608, -0.00392157, -0.27843137],\n         [ 0.62352941,  0.14509804, -0.09803922],\n         [ 0.76470588,  0.28627451,  0.05882353]]],\n\n\n       [[[-0.9372549 , -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ],\n         [-0.97647059, -1.        , -1.        ],\n         ...,\n         [-0.92941176, -0.99215686, -1.        ],\n         [-0.94509804, -1.        , -1.        ],\n         [-1.        , -1.        , -0.98431373]],\n\n        [[-0.79607843, -0.98431373, -0.98431373],\n         [-0.88235294, -0.96862745, -0.98431373],\n         [-0.45098039, -0.50588235, -0.58431373],\n         ...,\n         [-0.7254902 , -0.78823529, -0.70196078],\n         [-0.57647059, -0.69411765, -0.65490196],\n         [-0.92941176, -0.96862745, -0.91372549]],\n\n        [[-0.74901961, -0.91372549, -0.9372549 ],\n         [-0.78039216, -0.92156863, -0.9372549 ],\n         [-0.6       , -0.63921569, -0.6627451 ],\n         ...,\n         [-0.76470588, -0.81176471, -0.71764706],\n         [-0.73333333, -0.82745098, -0.71764706],\n         [-0.81960784, -0.8745098 , -0.74901961]],\n\n        ...,\n\n        [[-0.80392157, -0.83529412, -0.82745098],\n         [-0.85882353, -0.89019608, -0.88235294],\n         [-0.82745098, -0.85882353, -0.85098039],\n         ...,\n         [-0.63921569, -0.85882353, -0.94509804],\n         [-0.42745098, -0.54509804, -0.88235294],\n         [-0.48235294, -0.56862745, -0.92941176]],\n\n        [[-0.82745098, -0.85098039, -0.92156863],\n         [-0.8745098 , -0.90588235, -0.91372549],\n         [-0.86666667, -0.89803922, -0.90588235],\n         ...,\n         [-0.62352941, -0.79607843, -0.90588235],\n         [-0.63137255, -0.71764706, -0.9372549 ],\n         [-0.75686275, -0.81176471, -0.9372549 ]],\n\n        [[-0.79607843, -0.82745098, -0.85098039],\n         [-0.86666667, -0.89803922, -0.90588235],\n         [-0.88235294, -0.91372549, -0.92156863],\n         ...,\n         [-0.70980392, -0.92941176, -0.96078431],\n         [-0.68627451, -0.88235294, -0.85882353],\n         [-0.63137255, -0.75686275, -0.65490196]]],\n\n\n       [[[-0.42745098, -0.41960784, -0.46666667],\n         [-0.24705882, -0.27058824, -0.34117647],\n         [ 0.6       ,  0.59215686,  0.56078431],\n         ...,\n         [ 0.80392157,  0.81176471,  0.82745098],\n         [ 0.80392157,  0.81176471,  0.84313725],\n         [ 0.78823529,  0.81960784,  0.82745098]],\n\n        [[-0.54509804, -0.58431373, -0.63137255],\n         [-0.41176471, -0.41176471, -0.4745098 ],\n         [-0.2       , -0.23137255, -0.3254902 ],\n         ...,\n         [ 0.78039216,  0.81176471,  0.81960784],\n         [ 0.70196078,  0.73333333,  0.75686275],\n         [ 0.51372549,  0.55294118,  0.57647059]],\n\n        [[-0.27058824, -0.44313725, -0.62352941],\n         [-0.37254902, -0.41960784, -0.51372549],\n         [-0.36470588, -0.41960784, -0.49803922],\n         ...,\n         [ 0.81176471,  0.81960784,  0.83529412],\n         [ 0.80392157,  0.79607843,  0.83529412],\n         [ 0.70196078,  0.73333333,  0.75686275]],\n\n        ...,\n\n        [[-0.74901961, -0.71764706, -0.64705882],\n         [-0.80392157, -0.74901961, -0.67058824],\n         [-0.79607843, -0.74901961, -0.65490196],\n         ...,\n         [-0.52156863, -0.6627451 , -0.77254902],\n         [ 0.39607843,  0.24705882,  0.11372549],\n         [ 0.71764706,  0.60784314,  0.52156863]],\n\n        [[-0.78039216, -0.71764706, -0.63137255],\n         [-0.70980392, -0.65490196, -0.57647059],\n         [-0.81176471, -0.76470588, -0.65490196],\n         ...,\n         [ 0.29411765,  0.12156863,  0.01960784],\n         [ 0.59215686,  0.48235294,  0.41176471],\n         [ 0.7254902 ,  0.61568627,  0.59215686]],\n\n        [[-0.69411765, -0.63921569, -0.56078431],\n         [-0.70196078, -0.70196078, -0.60784314],\n         [-0.74117647, -0.71764706, -0.64705882],\n         ...,\n         [ 0.51372549,  0.40392157,  0.31764706],\n         [ 0.67843137,  0.61568627,  0.6       ],\n         [ 0.76470588,  0.65490196,  0.64705882]]]]), array([[[[ 0.28005204, -0.01295621,  0.5360961 ],\n         [ 0.7138143 , -0.32918018,  0.08042552],\n         [ 0.6813825 ,  0.42994848,  0.17496546],\n         ...,\n         [ 0.75120044, -0.2074037 ,  0.73411494],\n         [ 0.6202267 , -0.15057443, -0.02427469],\n         [ 0.37704888,  0.13028482,  0.39609212]],\n\n        [[ 0.798608  , -0.0048413 ,  0.30336818],\n         [ 0.9139696 ,  0.30283973,  0.15080553],\n         [ 0.39215103,  0.28539187,  0.37781233],\n         ...,\n         [ 0.90145683, -0.09665363,  0.3289767 ],\n         [-0.01507211,  0.59585404,  0.67706436],\n         [-0.52627254,  0.4035525 ,  0.5719068 ]],\n\n        [[ 0.7555575 , -0.52795196,  0.43682513],\n         [ 0.41943383, -0.00275957,  0.28202432],\n         [ 0.8449016 ,  0.4020259 , -0.32986307],\n         ...,\n         [ 0.1052077 ,  0.94883096,  0.76286906],\n         [-0.04619666,  0.7481997 , -0.7266152 ],\n         [-0.17623495,  0.56028736,  0.59310627]],\n\n        ...,\n\n        [[ 0.2909751 , -0.5842813 ,  0.3946403 ],\n         [-0.24082695, -0.08199424,  0.5840604 ],\n         [ 0.9111845 ,  0.6912433 ,  0.92412055],\n         ...,\n         [ 0.91500014,  0.91200167, -0.8868953 ],\n         [ 0.86651576,  0.41030794, -0.14312866],\n         [-0.18599217,  0.7101319 ,  0.01032009]],\n\n        [[ 0.5036033 , -0.32457975, -0.62310004],\n         [ 0.07955931,  0.71538   , -0.27250555],\n         [-0.3282044 ,  0.7913524 ,  0.6508543 ],\n         ...,\n         [ 0.43469596,  0.99647766, -0.57596296],\n         [ 0.82176423,  0.9422403 , -0.71396595],\n         [ 0.5203975 ,  0.76501244,  0.41422945]],\n\n        [[ 0.5494541 ,  0.606268  , -0.5817314 ],\n         [ 0.2197637 ,  0.05814296, -0.1381551 ],\n         [-0.6139494 ,  0.2679585 , -0.4904744 ],\n         ...,\n         [ 0.4727358 ,  0.46447867, -0.4251555 ],\n         [ 0.04693783,  0.5672575 , -0.56019217],\n         [ 0.13168946,  0.2460086 , -0.58633715]]],\n\n\n       [[[ 0.18709867, -0.13919784,  0.21326135],\n         [ 0.38496312, -0.06465629,  0.29490995],\n         [ 0.3686448 ,  0.30889472,  0.2318039 ],\n         ...,\n         [ 0.862891  ,  0.6628613 ,  0.42536083],\n         [ 0.3052695 ,  0.36013907, -0.22544855],\n         [ 0.04473574,  0.5282923 ,  0.09166476]],\n\n        [[ 0.27202237, -0.12902533,  0.2405799 ],\n         [ 0.2931427 , -0.40337607,  0.39754632],\n         [ 0.35103995,  0.40132898,  0.45857042],\n         ...,\n         [ 0.9444176 ,  0.59867996,  0.65695447],\n         [ 0.3239954 ,  0.58770716,  0.26058698],\n         [ 0.01199465,  0.79352945,  0.4366563 ]],\n\n        [[ 0.42462772, -0.20005746,  0.02098982],\n         [ 0.44561335,  0.37549317,  0.22094901],\n         [ 0.68862754,  0.04966352,  0.19684973],\n         ...,\n         [ 0.36331964,  0.9463984 , -0.01874124],\n         [ 0.82969874,  0.7728404 ,  0.60578847],\n         [ 0.52958775,  0.3288805 ,  0.46693346]],\n\n        ...,\n\n        [[-0.04922634, -0.50676066,  0.16763727],\n         [ 0.7654162 ,  0.09383211, -0.16851352],\n         [ 0.81068856,  0.21837115, -0.11404665],\n         ...,\n         [ 0.81920767,  0.9626284 ,  0.19121765],\n         [ 0.91598725,  0.8242136 ,  0.675939  ],\n         [ 0.98958766,  0.8504024 , -0.13849683]],\n\n        [[ 0.42106298, -0.23145925, -0.47753114],\n         [-0.09348758,  0.34995797,  0.5689166 ],\n         [-0.13490617,  0.38598004, -0.0739463 ],\n         ...,\n         [-0.872576  ,  0.99970996, -0.6376413 ],\n         [-0.5643231 ,  0.9686425 ,  0.4598599 ],\n         [ 0.17398652,  0.4451401 , -0.6272094 ]],\n\n        [[ 0.26290858,  0.1357264 , -0.08694506],\n         [ 0.09538344,  0.36150476, -0.49037078],\n         [ 0.4393836 ,  0.66015387, -0.56874573],\n         ...,\n         [-0.95418566,  0.73919576, -0.89956546],\n         [-0.41213933,  0.85994285, -0.58959854],\n         [-0.45036927,  0.8905244 , -0.53529286]]],\n\n\n       [[[ 0.50854367, -0.15723808,  0.3460986 ],\n         [ 0.5923668 , -0.05765957, -0.06700322],\n         [ 0.7864806 ,  0.20196047,  0.3031795 ],\n         ...,\n         [ 0.99599874, -0.36235088,  0.972334  ],\n         [ 0.8438084 , -0.8619196 ,  0.37582415],\n         [ 0.73434734,  0.05059353,  0.68843234]],\n\n        [[ 0.5494253 ,  0.06016738,  0.53668207],\n         [ 0.67744964, -0.024435  ,  0.68129265],\n         [ 0.8252342 , -0.47557768,  0.24468392],\n         ...,\n         [ 0.96790326,  0.94796735,  0.849233  ],\n         [ 0.04041001,  0.92726094,  0.5186056 ],\n         [-0.29125884,  0.85609055,  0.903522  ]],\n\n        [[ 0.24386355,  0.09603879,  0.638444  ],\n         [ 0.5438569 , -0.05604295, -0.08032707],\n         [ 0.9669115 ,  0.32108423,  0.02866204],\n         ...,\n         [ 0.9953327 ,  0.9973665 ,  0.27985686],\n         [-0.7513156 ,  0.97620666, -0.59840184],\n         [ 0.52101797,  0.7611095 ,  0.88859135]],\n\n        ...,\n\n        [[ 0.94218403,  0.15800168, -0.3558232 ],\n         [ 0.5634679 ,  0.1634108 ,  0.8828248 ],\n         [ 0.98365676,  0.91767776, -0.37972066],\n         ...,\n         [ 0.99197435,  0.8894995 , -0.33795202],\n         [ 0.57987833,  0.98631364, -0.87175894],\n         [ 0.7506098 ,  0.7640584 ,  0.89557385]],\n\n        [[-0.01933168, -0.21847302,  0.4099324 ],\n         [-0.6521086 ,  0.9223896 ,  0.8712159 ],\n         [ 0.5165878 ,  0.9419717 ,  0.5121213 ],\n         ...,\n         [-0.34982458,  0.9981403 ,  0.8152248 ],\n         [ 0.17366739,  0.6005548 ,  0.02385741],\n         [ 0.8690081 ,  0.95914674,  0.3823066 ]],\n\n        [[ 0.670771  ,  0.46017122, -0.23274584],\n         [-0.03414054,  0.74885744,  0.06870717],\n         [-0.34645772,  0.9222028 , -0.845058  ],\n         ...,\n         [-0.17068623,  0.87573826, -0.55411583],\n         [ 0.7688842 ,  0.58232135, -0.08363857],\n         [ 0.33503023,  0.7668581 , -0.2618821 ]]],\n\n\n       ...,\n\n\n       [[[ 0.23417884,  0.17876536,  0.11649466],\n         [ 0.5914266 , -0.40924248,  0.17160852],\n         [ 0.63532114,  0.34961477,  0.41503245],\n         ...,\n         [ 0.7065354 ,  0.46054253,  0.6750122 ],\n         [ 0.14220487,  0.09347253,  0.7391535 ],\n         [-0.11980761,  0.32697633,  0.13327156]],\n\n        [[ 0.71638817, -0.21592437,  0.43343046],\n         [ 0.48729447, -0.56404185,  0.47115207],\n         [ 0.9165136 ,  0.59082544,  0.63809204],\n         ...,\n         [ 0.5665324 ,  0.47289944,  0.37342313],\n         [ 0.46962252, -0.14107609, -0.0352383 ],\n         [ 0.47494397,  0.149785  ,  0.6033565 ]],\n\n        [[ 0.654126  ,  0.06903381,  0.27928805],\n         [ 0.23318654,  0.15353401,  0.27010903],\n         [ 0.653843  ,  0.7067269 ,  0.60990196],\n         ...,\n         [ 0.94115245,  0.8625983 , -0.3548162 ],\n         [ 0.3179231 ,  0.33286607, -0.4719782 ],\n         [ 0.40788606, -0.1885545 ,  0.14062953]],\n\n        ...,\n\n        [[ 0.2956994 , -0.4715173 ,  0.77048314],\n         [ 0.66679734,  0.553596  ,  0.5519909 ],\n         [ 0.96092623,  0.347186  ,  0.6526715 ],\n         ...,\n         [ 0.99772215, -0.572089  ,  0.07590809],\n         [ 0.96562964,  0.7960083 , -0.8240127 ],\n         [ 0.05156404,  0.83744776,  0.13072442]],\n\n        [[ 0.5037143 , -0.58291775, -0.42885998],\n         [ 0.4919658 ,  0.35213837, -0.7591936 ],\n         [-0.92565376,  0.88493574, -0.6352117 ],\n         ...,\n         [ 0.9987292 ,  0.9712032 ,  0.5909334 ],\n         [ 0.94052464,  0.10441297,  0.76670766],\n         [ 0.17932929,  0.9813099 ,  0.95210403]],\n\n        [[ 0.7935247 ,  0.47642842, -0.6121167 ],\n         [ 0.81518096, -0.23811792, -0.8078477 ],\n         [ 0.23053178, -0.24941792, -0.45480022],\n         ...,\n         [ 0.7165835 , -0.44795972, -0.98817915],\n         [-0.01567555,  0.39961734, -0.7695575 ],\n         [ 0.07669327,  0.28870076, -0.27438408]]],\n\n\n       [[[-0.07916274,  0.06127489,  0.06721335],\n         [ 0.2663672 , -0.36294428,  0.2730812 ],\n         [ 0.4274954 , -0.199237  ,  0.3858946 ],\n         ...,\n         [ 0.66138583,  0.57767266,  0.6823033 ],\n         [-0.15571557, -0.05171663,  0.5929194 ],\n         [ 0.20335785,  0.08930219,  0.5612966 ]],\n\n        [[ 0.32803303, -0.14009355,  0.12747727],\n         [ 0.13388939, -0.12808745,  0.31751183],\n         [ 0.31059846,  0.2476053 ,  0.06148256],\n         ...,\n         [-0.3071546 ,  0.6127426 , -0.3971068 ],\n         [ 0.15058222,  0.6484544 , -0.64954734],\n         [ 0.6301742 ,  0.19707787,  0.6394374 ]],\n\n        [[ 0.29541293, -0.25610512,  0.02741918],\n         [ 0.51532173,  0.36917076,  0.2740527 ],\n         [ 0.507323  ,  0.30632663,  0.48969314],\n         ...,\n         [ 0.91772085,  0.8694348 ,  0.27336812],\n         [-0.07765196,  0.8874428 , -0.36993268],\n         [ 0.27321702,  0.7862604 ,  0.7157703 ]],\n\n        ...,\n\n        [[ 0.3052201 , -0.2849969 ,  0.02883673],\n         [ 0.9027616 , -0.62882227,  0.14880867],\n         [ 0.80590624,  0.5455357 ,  0.01459164],\n         ...,\n         [ 0.9555146 ,  0.9661299 , -0.12157329],\n         [ 0.11750849,  0.6591238 , -0.8975571 ],\n         [ 0.86323035,  0.87395483,  0.09352628]],\n\n        [[ 0.3224021 , -0.704681  , -0.27405554],\n         [ 0.31818643,  0.50933903,  0.06042401],\n         [ 0.2807724 ,  0.5371993 , -0.17293894],\n         ...,\n         [ 0.1832646 ,  0.9845777 , -0.65311337],\n         [-0.2699855 ,  0.4876237 ,  0.55397874],\n         [ 0.3970491 ,  0.93286735, -0.18568991]],\n\n        [[ 0.2721977 , -0.23631458, -0.2288712 ],\n         [-0.00543356,  0.46390823, -0.67486215],\n         [ 0.4907456 ,  0.50095206, -0.65681934],\n         ...,\n         [ 0.18105246,  0.883262  , -0.7136467 ],\n         [-0.70929563,  0.91674685,  0.01274434],\n         [ 0.55528104,  0.6824069 , -0.77079993]]],\n\n\n       [[[ 0.29154435,  0.03771598,  0.38924667],\n         [ 0.16212763,  0.52359515,  0.2615225 ],\n         [ 0.7452874 ,  0.18767999,  0.1486834 ],\n         ...,\n         [ 0.73134184,  0.14331108,  0.974814  ],\n         [ 0.70718825, -0.53215635,  0.3624317 ],\n         [-0.22797051,  0.03587913,  0.5811585 ]],\n\n        [[ 0.5703225 , -0.23076014,  0.21538258],\n         [ 0.40888655, -0.06397503, -0.04663591],\n         [ 0.76388633,  0.30449575,  0.51072127],\n         ...,\n         [ 0.6275543 ,  0.6621061 ,  0.14226295],\n         [ 0.16916338,  0.78098434,  0.7759447 ],\n         [-0.38196898,  0.29494008,  0.6400463 ]],\n\n        [[ 0.35482153,  0.2507629 ,  0.10497419],\n         [ 0.5569031 ,  0.16839586, -0.54338104],\n         [ 0.5724411 ,  0.43847224,  0.06045865],\n         ...,\n         [ 0.9120543 ,  0.7269112 , -0.07969406],\n         [ 0.47315556,  0.89779645,  0.2635537 ],\n         [ 0.3811015 ,  0.5823222 ,  0.91262597]],\n\n        ...,\n\n        [[ 0.43041262,  0.49742815, -0.3106841 ],\n         [ 0.8152806 , -0.3664783 ,  0.6685815 ],\n         [ 0.897424  ,  0.3917484 ,  0.31995434],\n         ...,\n         [ 0.9984833 ,  0.997961  ,  0.46868393],\n         [ 0.9185591 ,  0.53729343, -0.6477249 ],\n         [ 0.68503755,  0.26151663, -0.8242519 ]],\n\n        [[ 0.18841839, -0.01515698,  0.26325986],\n         [-0.02830816,  0.60306543,  0.3835285 ],\n         [ 0.14363052,  0.6274838 , -0.3897818 ],\n         ...,\n         [-0.43897757,  0.97890043,  0.27643386],\n         [ 0.12157195,  0.93375087, -0.4293472 ],\n         [ 0.60540456,  0.77511334,  0.16037741]],\n\n        [[ 0.50782406, -0.0038881 ,  0.00762904],\n         [-0.04364663,  0.15338175, -0.10123171],\n         [ 0.2676707 ,  0.70861197, -0.46737352],\n         ...,\n         [ 0.8645493 ,  0.722528  , -0.60077596],\n         [-0.6732556 ,  0.5519895 , -0.6607604 ],\n         [ 0.06130024,  0.156236  , -0.6213455 ]]]], dtype=float32)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 474\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ef8b8e05ec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maveraged_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomWeightedAverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_samples_for_discriminator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# averaged_samples.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer random_weighted_average_3 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[[ 0.34901961,  0.00392157, -0.30196078],\n         [ 0.5372549 ,  0.12156863, -0.22352941],\n         [ 0.64705882,  0.19215686, -0.12156863],\n         ...,\n         [-0.30980392, -0.58431373, -0.83529412],\n         [-0.3254902 , -0.6       , -0.81960784],\n         [-0.2       , -0.48235294, -0.73333333]],\n\n        [[-0.00392157, -0.28627451, -0.5372549 ],\n         [-0.30980392, -0.6       , -0.81176471],\n         [ 0.23137255, -0.1372549 , -0.37254902],\n         ...,\n         [-0.3254902 , -0.58431373, -0.84313725],\n         [-0.34901961, -0.61568627, -0.83529412],\n         [-0.17647059, -0.48235294, -0.7254902 ]],\n\n        [[-0.16862745, -0.4745098 , -0.71764706],\n         [-0.60784314, -0.82745098, -0.92156863],\n         [-0.34901961, -0.63921569, -0.78039216],\n         ...,\n         [-0.3254902 , -0.59215686, -0.81176471],\n         [-0.35686275, -0.6       , -0.82745098],\n         [-0.16078431, -0.48235294, -0.71764706]],\n\n        ...,\n\n        [[-0.41176471, -0.48235294, -0.5372549 ],\n         [-0.41176471, -0.55294118, -0.6627451 ],\n         [-0.34117647, -0.41960784, -0.41176471],\n         ...,\n         [ 0.10588235, -0.18431373, -0.39607843],\n         [ 0.1372549 , -0.14509804, -0.31764706],\n         [ 0.15294118, -0.09803922, -0.21568627]],\n\n        [[-0.90588235, -0.98431373, -1.        ],\n         [-0.56862745, -0.63137255, -0.54509804],\n         [-0.78823529, -0.71764706, -0.4745098 ],\n         ...,\n         [ 0.0745098 , -0.2       , -0.35686275],\n         [ 0.19215686, -0.12941176, -0.27058824],\n         [ 0.12941176, -0.12156863, -0.22352941]],\n\n        [[-0.34901961, -0.43529412, -0.40392157],\n         [-0.91372549, -0.89019608, -0.77254902],\n         [-0.95294118, -0.89803922, -0.75686275],\n         ...,\n         [ 0.0745098 , -0.17647059, -0.37254902],\n         [-0.04313725, -0.23921569, -0.27843137],\n         [-0.04313725, -0.24705882, -0.25490196]]],\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ],\n         [-0.36470588, -0.49803922, -0.70196078],\n         ...,\n         [-0.0745098 , -0.00392157, -0.16862745],\n         [-0.0745098 , -0.00392157, -0.16862745],\n         [-0.09019608, -0.01960784, -0.18431373]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ],\n         [-0.38039216, -0.51372549, -0.71764706],\n         ...,\n         [-0.06666667,  0.00392157, -0.16078431],\n         [-0.06666667,  0.00392157, -0.16078431],\n         [-0.08235294, -0.01176471, -0.17647059]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-0.97647059, -1.        , -1.        ],\n         [-0.38039216, -0.51372549, -0.71764706],\n         ...,\n         [-0.06666667,  0.00392157, -0.16078431],\n         [-0.05882353,  0.01176471, -0.15294118],\n         [-0.06666667,  0.00392157, -0.16078431]],\n\n        ...,\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -0.98431373],\n         [-0.78823529, -0.79607843, -0.75686275],\n         ...,\n         [ 0.22352941, -0.12156863, -0.14509804],\n         [ 0.08235294, -0.14509804, -0.20784314],\n         [-0.67843137, -0.70196078, -0.74117647]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -0.98431373],\n         [-0.78823529, -0.79607843, -0.75686275],\n         ...,\n         [ 0.34901961,  0.2       ,  0.09019608],\n         [-0.48235294, -0.5372549 , -0.61568627],\n         [-0.74901961, -0.73333333, -0.75686275]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-0.99215686, -0.99215686, -0.97647059],\n         [-0.80392157, -0.81176471, -0.77254902],\n         ...,\n         [ 0.05882353, -0.00392157, -0.09019608],\n         [-0.85882353, -0.85882353, -0.8745098 ],\n         [-0.8745098 , -0.8745098 , -0.8745098 ]]],\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[ 0.51372549,  0.55294118,  0.37254902],\n         [ 0.57647059,  0.61568627,  0.45882353],\n         [ 0.63921569,  0.67843137,  0.50588235],\n         ...,\n         [ 0.80392157,  0.85882353,  0.73333333],\n         [ 0.78039216,  0.83529412,  0.70980392],\n         [ 0.77254902,  0.82745098,  0.70196078]],\n\n        ...,\n\n        [[ 0.58431373,  0.19215686,  0.2       ],\n         [ 0.67058824,  0.63921569,  0.44313725],\n         [-0.63137255, -0.62352941, -0.68627451],\n         ...,\n         [-0.74901961, -0.78039216, -0.80392157],\n         [-0.75686275, -0.78039216, -0.81960784],\n         [-0.74901961, -0.77254902, -0.81176471]],\n\n        [[ 0.00392157, -0.50588235, -0.5372549 ],\n         [ 0.31764706, -0.05882353, -0.1372549 ],\n         [-0.70196078, -0.73333333, -0.75686275],\n         ...,\n         [-0.77254902, -0.76470588, -0.80392157],\n         [-0.79607843, -0.79607843, -0.81176471],\n         [-0.80392157, -0.80392157, -0.81960784]],\n\n        [[-0.14509804, -0.59215686, -0.6627451 ],\n         [-0.40392157, -0.42745098, -0.49803922],\n         [-0.78039216, -0.77254902, -0.81960784],\n         ...,\n         [-0.81176471, -0.79607843, -0.81960784],\n         [-0.80392157, -0.78823529, -0.79607843],\n         [-0.78823529, -0.78039216, -0.76470588]]],\n\n\n       ...,\n\n\n       [[[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         ...,\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ],\n         [-1.        , -1.        , -1.        ]],\n\n        [[-0.98431373, -1.        , -0.97647059],\n         [-0.98431373, -1.        , -0.97647059],\n         [-0.97647059, -1.        , -0.98431373],\n         ...,\n         [-0.96862745, -1.        , -1.        ],\n         [-0.95294118, -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ]],\n\n        ...,\n\n        [[-0.49803922, -0.45098039, -0.46666667],\n         [-0.52941176, -0.48235294, -0.49803922],\n         [-0.27058824, -0.27058824, -0.34901961],\n         ...,\n         [ 0.86666667,  0.4745098 ,  0.2       ],\n         [ 0.98431373,  0.62352941,  0.44313725],\n         [ 0.70980392,  0.18431373,  0.23921569]],\n\n        [[-0.38039216, -0.34901961, -0.3254902 ],\n         [-0.34901961, -0.35686275, -0.39607843],\n         [ 0.54509804,  0.35686275,  0.15294118],\n         ...,\n         [ 0.96078431,  0.52156863,  0.24705882],\n         [ 0.92941176,  0.58431373,  0.37254902],\n         [ 0.99215686,  0.70196078,  0.56078431]],\n\n        [[-0.2627451 , -0.27843137, -0.37254902],\n         [ 0.51372549,  0.28627451,  0.01960784],\n         [ 0.52941176,  0.12941176, -0.22352941],\n         ...,\n         [ 0.49019608, -0.00392157, -0.27843137],\n         [ 0.62352941,  0.14509804, -0.09803922],\n         [ 0.76470588,  0.28627451,  0.05882353]]],\n\n\n       [[[-0.9372549 , -1.        , -1.        ],\n         [-0.96862745, -1.        , -1.        ],\n         [-0.97647059, -1.        , -1.        ],\n         ...,\n         [-0.92941176, -0.99215686, -1.        ],\n         [-0.94509804, -1.        , -1.        ],\n         [-1.        , -1.        , -0.98431373]],\n\n        [[-0.79607843, -0.98431373, -0.98431373],\n         [-0.88235294, -0.96862745, -0.98431373],\n         [-0.45098039, -0.50588235, -0.58431373],\n         ...,\n         [-0.7254902 , -0.78823529, -0.70196078],\n         [-0.57647059, -0.69411765, -0.65490196],\n         [-0.92941176, -0.96862745, -0.91372549]],\n\n        [[-0.74901961, -0.91372549, -0.9372549 ],\n         [-0.78039216, -0.92156863, -0.9372549 ],\n         [-0.6       , -0.63921569, -0.6627451 ],\n         ...,\n         [-0.76470588, -0.81176471, -0.71764706],\n         [-0.73333333, -0.82745098, -0.71764706],\n         [-0.81960784, -0.8745098 , -0.74901961]],\n\n        ...,\n\n        [[-0.80392157, -0.83529412, -0.82745098],\n         [-0.85882353, -0.89019608, -0.88235294],\n         [-0.82745098, -0.85882353, -0.85098039],\n         ...,\n         [-0.63921569, -0.85882353, -0.94509804],\n         [-0.42745098, -0.54509804, -0.88235294],\n         [-0.48235294, -0.56862745, -0.92941176]],\n\n        [[-0.82745098, -0.85098039, -0.92156863],\n         [-0.8745098 , -0.90588235, -0.91372549],\n         [-0.86666667, -0.89803922, -0.90588235],\n         ...,\n         [-0.62352941, -0.79607843, -0.90588235],\n         [-0.63137255, -0.71764706, -0.9372549 ],\n         [-0.75686275, -0.81176471, -0.9372549 ]],\n\n        [[-0.79607843, -0.82745098, -0.85098039],\n         [-0.86666667, -0.89803922, -0.90588235],\n         [-0.88235294, -0.91372549, -0.92156863],\n         ...,\n         [-0.70980392, -0.92941176, -0.96078431],\n         [-0.68627451, -0.88235294, -0.85882353],\n         [-0.63137255, -0.75686275, -0.65490196]]],\n\n\n       [[[-0.42745098, -0.41960784, -0.46666667],\n         [-0.24705882, -0.27058824, -0.34117647],\n         [ 0.6       ,  0.59215686,  0.56078431],\n         ...,\n         [ 0.80392157,  0.81176471,  0.82745098],\n         [ 0.80392157,  0.81176471,  0.84313725],\n         [ 0.78823529,  0.81960784,  0.82745098]],\n\n        [[-0.54509804, -0.58431373, -0.63137255],\n         [-0.41176471, -0.41176471, -0.4745098 ],\n         [-0.2       , -0.23137255, -0.3254902 ],\n         ...,\n         [ 0.78039216,  0.81176471,  0.81960784],\n         [ 0.70196078,  0.73333333,  0.75686275],\n         [ 0.51372549,  0.55294118,  0.57647059]],\n\n        [[-0.27058824, -0.44313725, -0.62352941],\n         [-0.37254902, -0.41960784, -0.51372549],\n         [-0.36470588, -0.41960784, -0.49803922],\n         ...,\n         [ 0.81176471,  0.81960784,  0.83529412],\n         [ 0.80392157,  0.79607843,  0.83529412],\n         [ 0.70196078,  0.73333333,  0.75686275]],\n\n        ...,\n\n        [[-0.74901961, -0.71764706, -0.64705882],\n         [-0.80392157, -0.74901961, -0.67058824],\n         [-0.79607843, -0.74901961, -0.65490196],\n         ...,\n         [-0.52156863, -0.6627451 , -0.77254902],\n         [ 0.39607843,  0.24705882,  0.11372549],\n         [ 0.71764706,  0.60784314,  0.52156863]],\n\n        [[-0.78039216, -0.71764706, -0.63137255],\n         [-0.70980392, -0.65490196, -0.57647059],\n         [-0.81176471, -0.76470588, -0.65490196],\n         ...,\n         [ 0.29411765,  0.12156863,  0.01960784],\n         [ 0.59215686,  0.48235294,  0.41176471],\n         [ 0.7254902 ,  0.61568627,  0.59215686]],\n\n        [[-0.69411765, -0.63921569, -0.56078431],\n         [-0.70196078, -0.70196078, -0.60784314],\n         [-0.74117647, -0.71764706, -0.64705882],\n         ...,\n         [ 0.51372549,  0.40392157,  0.31764706],\n         [ 0.67843137,  0.61568627,  0.6       ],\n         [ 0.76470588,  0.65490196,  0.64705882]]]]), array([[[[ 0.28005204, -0.01295621,  0.5360961 ],\n         [ 0.7138143 , -0.32918018,  0.08042552],\n         [ 0.6813825 ,  0.42994848,  0.17496546],\n         ...,\n         [ 0.75120044, -0.2074037 ,  0.73411494],\n         [ 0.6202267 , -0.15057443, -0.02427469],\n         [ 0.37704888,  0.13028482,  0.39609212]],\n\n        [[ 0.798608  , -0.0048413 ,  0.30336818],\n         [ 0.9139696 ,  0.30283973,  0.15080553],\n         [ 0.39215103,  0.28539187,  0.37781233],\n         ...,\n         [ 0.90145683, -0.09665363,  0.3289767 ],\n         [-0.01507211,  0.59585404,  0.67706436],\n         [-0.52627254,  0.4035525 ,  0.5719068 ]],\n\n        [[ 0.7555575 , -0.52795196,  0.43682513],\n         [ 0.41943383, -0.00275957,  0.28202432],\n         [ 0.8449016 ,  0.4020259 , -0.32986307],\n         ...,\n         [ 0.1052077 ,  0.94883096,  0.76286906],\n         [-0.04619666,  0.7481997 , -0.7266152 ],\n         [-0.17623495,  0.56028736,  0.59310627]],\n\n        ...,\n\n        [[ 0.2909751 , -0.5842813 ,  0.3946403 ],\n         [-0.24082695, -0.08199424,  0.5840604 ],\n         [ 0.9111845 ,  0.6912433 ,  0.92412055],\n         ...,\n         [ 0.91500014,  0.91200167, -0.8868953 ],\n         [ 0.86651576,  0.41030794, -0.14312866],\n         [-0.18599217,  0.7101319 ,  0.01032009]],\n\n        [[ 0.5036033 , -0.32457975, -0.62310004],\n         [ 0.07955931,  0.71538   , -0.27250555],\n         [-0.3282044 ,  0.7913524 ,  0.6508543 ],\n         ...,\n         [ 0.43469596,  0.99647766, -0.57596296],\n         [ 0.82176423,  0.9422403 , -0.71396595],\n         [ 0.5203975 ,  0.76501244,  0.41422945]],\n\n        [[ 0.5494541 ,  0.606268  , -0.5817314 ],\n         [ 0.2197637 ,  0.05814296, -0.1381551 ],\n         [-0.6139494 ,  0.2679585 , -0.4904744 ],\n         ...,\n         [ 0.4727358 ,  0.46447867, -0.4251555 ],\n         [ 0.04693783,  0.5672575 , -0.56019217],\n         [ 0.13168946,  0.2460086 , -0.58633715]]],\n\n\n       [[[ 0.18709867, -0.13919784,  0.21326135],\n         [ 0.38496312, -0.06465629,  0.29490995],\n         [ 0.3686448 ,  0.30889472,  0.2318039 ],\n         ...,\n         [ 0.862891  ,  0.6628613 ,  0.42536083],\n         [ 0.3052695 ,  0.36013907, -0.22544855],\n         [ 0.04473574,  0.5282923 ,  0.09166476]],\n\n        [[ 0.27202237, -0.12902533,  0.2405799 ],\n         [ 0.2931427 , -0.40337607,  0.39754632],\n         [ 0.35103995,  0.40132898,  0.45857042],\n         ...,\n         [ 0.9444176 ,  0.59867996,  0.65695447],\n         [ 0.3239954 ,  0.58770716,  0.26058698],\n         [ 0.01199465,  0.79352945,  0.4366563 ]],\n\n        [[ 0.42462772, -0.20005746,  0.02098982],\n         [ 0.44561335,  0.37549317,  0.22094901],\n         [ 0.68862754,  0.04966352,  0.19684973],\n         ...,\n         [ 0.36331964,  0.9463984 , -0.01874124],\n         [ 0.82969874,  0.7728404 ,  0.60578847],\n         [ 0.52958775,  0.3288805 ,  0.46693346]],\n\n        ...,\n\n        [[-0.04922634, -0.50676066,  0.16763727],\n         [ 0.7654162 ,  0.09383211, -0.16851352],\n         [ 0.81068856,  0.21837115, -0.11404665],\n         ...,\n         [ 0.81920767,  0.9626284 ,  0.19121765],\n         [ 0.91598725,  0.8242136 ,  0.675939  ],\n         [ 0.98958766,  0.8504024 , -0.13849683]],\n\n        [[ 0.42106298, -0.23145925, -0.47753114],\n         [-0.09348758,  0.34995797,  0.5689166 ],\n         [-0.13490617,  0.38598004, -0.0739463 ],\n         ...,\n         [-0.872576  ,  0.99970996, -0.6376413 ],\n         [-0.5643231 ,  0.9686425 ,  0.4598599 ],\n         [ 0.17398652,  0.4451401 , -0.6272094 ]],\n\n        [[ 0.26290858,  0.1357264 , -0.08694506],\n         [ 0.09538344,  0.36150476, -0.49037078],\n         [ 0.4393836 ,  0.66015387, -0.56874573],\n         ...,\n         [-0.95418566,  0.73919576, -0.89956546],\n         [-0.41213933,  0.85994285, -0.58959854],\n         [-0.45036927,  0.8905244 , -0.53529286]]],\n\n\n       [[[ 0.50854367, -0.15723808,  0.3460986 ],\n         [ 0.5923668 , -0.05765957, -0.06700322],\n         [ 0.7864806 ,  0.20196047,  0.3031795 ],\n         ...,\n         [ 0.99599874, -0.36235088,  0.972334  ],\n         [ 0.8438084 , -0.8619196 ,  0.37582415],\n         [ 0.73434734,  0.05059353,  0.68843234]],\n\n        [[ 0.5494253 ,  0.06016738,  0.53668207],\n         [ 0.67744964, -0.024435  ,  0.68129265],\n         [ 0.8252342 , -0.47557768,  0.24468392],\n         ...,\n         [ 0.96790326,  0.94796735,  0.849233  ],\n         [ 0.04041001,  0.92726094,  0.5186056 ],\n         [-0.29125884,  0.85609055,  0.903522  ]],\n\n        [[ 0.24386355,  0.09603879,  0.638444  ],\n         [ 0.5438569 , -0.05604295, -0.08032707],\n         [ 0.9669115 ,  0.32108423,  0.02866204],\n         ...,\n         [ 0.9953327 ,  0.9973665 ,  0.27985686],\n         [-0.7513156 ,  0.97620666, -0.59840184],\n         [ 0.52101797,  0.7611095 ,  0.88859135]],\n\n        ...,\n\n        [[ 0.94218403,  0.15800168, -0.3558232 ],\n         [ 0.5634679 ,  0.1634108 ,  0.8828248 ],\n         [ 0.98365676,  0.91767776, -0.37972066],\n         ...,\n         [ 0.99197435,  0.8894995 , -0.33795202],\n         [ 0.57987833,  0.98631364, -0.87175894],\n         [ 0.7506098 ,  0.7640584 ,  0.89557385]],\n\n        [[-0.01933168, -0.21847302,  0.4099324 ],\n         [-0.6521086 ,  0.9223896 ,  0.8712159 ],\n         [ 0.5165878 ,  0.9419717 ,  0.5121213 ],\n         ...,\n         [-0.34982458,  0.9981403 ,  0.8152248 ],\n         [ 0.17366739,  0.6005548 ,  0.02385741],\n         [ 0.8690081 ,  0.95914674,  0.3823066 ]],\n\n        [[ 0.670771  ,  0.46017122, -0.23274584],\n         [-0.03414054,  0.74885744,  0.06870717],\n         [-0.34645772,  0.9222028 , -0.845058  ],\n         ...,\n         [-0.17068623,  0.87573826, -0.55411583],\n         [ 0.7688842 ,  0.58232135, -0.08363857],\n         [ 0.33503023,  0.7668581 , -0.2618821 ]]],\n\n\n       ...,\n\n\n       [[[ 0.23417884,  0.17876536,  0.11649466],\n         [ 0.5914266 , -0.40924248,  0.17160852],\n         [ 0.63532114,  0.34961477,  0.41503245],\n         ...,\n         [ 0.7065354 ,  0.46054253,  0.6750122 ],\n         [ 0.14220487,  0.09347253,  0.7391535 ],\n         [-0.11980761,  0.32697633,  0.13327156]],\n\n        [[ 0.71638817, -0.21592437,  0.43343046],\n         [ 0.48729447, -0.56404185,  0.47115207],\n         [ 0.9165136 ,  0.59082544,  0.63809204],\n         ...,\n         [ 0.5665324 ,  0.47289944,  0.37342313],\n         [ 0.46962252, -0.14107609, -0.0352383 ],\n         [ 0.47494397,  0.149785  ,  0.6033565 ]],\n\n        [[ 0.654126  ,  0.06903381,  0.27928805],\n         [ 0.23318654,  0.15353401,  0.27010903],\n         [ 0.653843  ,  0.7067269 ,  0.60990196],\n         ...,\n         [ 0.94115245,  0.8625983 , -0.3548162 ],\n         [ 0.3179231 ,  0.33286607, -0.4719782 ],\n         [ 0.40788606, -0.1885545 ,  0.14062953]],\n\n        ...,\n\n        [[ 0.2956994 , -0.4715173 ,  0.77048314],\n         [ 0.66679734,  0.553596  ,  0.5519909 ],\n         [ 0.96092623,  0.347186  ,  0.6526715 ],\n         ...,\n         [ 0.99772215, -0.572089  ,  0.07590809],\n         [ 0.96562964,  0.7960083 , -0.8240127 ],\n         [ 0.05156404,  0.83744776,  0.13072442]],\n\n        [[ 0.5037143 , -0.58291775, -0.42885998],\n         [ 0.4919658 ,  0.35213837, -0.7591936 ],\n         [-0.92565376,  0.88493574, -0.6352117 ],\n         ...,\n         [ 0.9987292 ,  0.9712032 ,  0.5909334 ],\n         [ 0.94052464,  0.10441297,  0.76670766],\n         [ 0.17932929,  0.9813099 ,  0.95210403]],\n\n        [[ 0.7935247 ,  0.47642842, -0.6121167 ],\n         [ 0.81518096, -0.23811792, -0.8078477 ],\n         [ 0.23053178, -0.24941792, -0.45480022],\n         ...,\n         [ 0.7165835 , -0.44795972, -0.98817915],\n         [-0.01567555,  0.39961734, -0.7695575 ],\n         [ 0.07669327,  0.28870076, -0.27438408]]],\n\n\n       [[[-0.07916274,  0.06127489,  0.06721335],\n         [ 0.2663672 , -0.36294428,  0.2730812 ],\n         [ 0.4274954 , -0.199237  ,  0.3858946 ],\n         ...,\n         [ 0.66138583,  0.57767266,  0.6823033 ],\n         [-0.15571557, -0.05171663,  0.5929194 ],\n         [ 0.20335785,  0.08930219,  0.5612966 ]],\n\n        [[ 0.32803303, -0.14009355,  0.12747727],\n         [ 0.13388939, -0.12808745,  0.31751183],\n         [ 0.31059846,  0.2476053 ,  0.06148256],\n         ...,\n         [-0.3071546 ,  0.6127426 , -0.3971068 ],\n         [ 0.15058222,  0.6484544 , -0.64954734],\n         [ 0.6301742 ,  0.19707787,  0.6394374 ]],\n\n        [[ 0.29541293, -0.25610512,  0.02741918],\n         [ 0.51532173,  0.36917076,  0.2740527 ],\n         [ 0.507323  ,  0.30632663,  0.48969314],\n         ...,\n         [ 0.91772085,  0.8694348 ,  0.27336812],\n         [-0.07765196,  0.8874428 , -0.36993268],\n         [ 0.27321702,  0.7862604 ,  0.7157703 ]],\n\n        ...,\n\n        [[ 0.3052201 , -0.2849969 ,  0.02883673],\n         [ 0.9027616 , -0.62882227,  0.14880867],\n         [ 0.80590624,  0.5455357 ,  0.01459164],\n         ...,\n         [ 0.9555146 ,  0.9661299 , -0.12157329],\n         [ 0.11750849,  0.6591238 , -0.8975571 ],\n         [ 0.86323035,  0.87395483,  0.09352628]],\n\n        [[ 0.3224021 , -0.704681  , -0.27405554],\n         [ 0.31818643,  0.50933903,  0.06042401],\n         [ 0.2807724 ,  0.5371993 , -0.17293894],\n         ...,\n         [ 0.1832646 ,  0.9845777 , -0.65311337],\n         [-0.2699855 ,  0.4876237 ,  0.55397874],\n         [ 0.3970491 ,  0.93286735, -0.18568991]],\n\n        [[ 0.2721977 , -0.23631458, -0.2288712 ],\n         [-0.00543356,  0.46390823, -0.67486215],\n         [ 0.4907456 ,  0.50095206, -0.65681934],\n         ...,\n         [ 0.18105246,  0.883262  , -0.7136467 ],\n         [-0.70929563,  0.91674685,  0.01274434],\n         [ 0.55528104,  0.6824069 , -0.77079993]]],\n\n\n       [[[ 0.29154435,  0.03771598,  0.38924667],\n         [ 0.16212763,  0.52359515,  0.2615225 ],\n         [ 0.7452874 ,  0.18767999,  0.1486834 ],\n         ...,\n         [ 0.73134184,  0.14331108,  0.974814  ],\n         [ 0.70718825, -0.53215635,  0.3624317 ],\n         [-0.22797051,  0.03587913,  0.5811585 ]],\n\n        [[ 0.5703225 , -0.23076014,  0.21538258],\n         [ 0.40888655, -0.06397503, -0.04663591],\n         [ 0.76388633,  0.30449575,  0.51072127],\n         ...,\n         [ 0.6275543 ,  0.6621061 ,  0.14226295],\n         [ 0.16916338,  0.78098434,  0.7759447 ],\n         [-0.38196898,  0.29494008,  0.6400463 ]],\n\n        [[ 0.35482153,  0.2507629 ,  0.10497419],\n         [ 0.5569031 ,  0.16839586, -0.54338104],\n         [ 0.5724411 ,  0.43847224,  0.06045865],\n         ...,\n         [ 0.9120543 ,  0.7269112 , -0.07969406],\n         [ 0.47315556,  0.89779645,  0.2635537 ],\n         [ 0.3811015 ,  0.5823222 ,  0.91262597]],\n\n        ...,\n\n        [[ 0.43041262,  0.49742815, -0.3106841 ],\n         [ 0.8152806 , -0.3664783 ,  0.6685815 ],\n         [ 0.897424  ,  0.3917484 ,  0.31995434],\n         ...,\n         [ 0.9984833 ,  0.997961  ,  0.46868393],\n         [ 0.9185591 ,  0.53729343, -0.6477249 ],\n         [ 0.68503755,  0.26151663, -0.8242519 ]],\n\n        [[ 0.18841839, -0.01515698,  0.26325986],\n         [-0.02830816,  0.60306543,  0.3835285 ],\n         [ 0.14363052,  0.6274838 , -0.3897818 ],\n         ...,\n         [-0.43897757,  0.97890043,  0.27643386],\n         [ 0.12157195,  0.93375087, -0.4293472 ],\n         [ 0.60540456,  0.77511334,  0.16037741]],\n\n        [[ 0.50782406, -0.0038881 ,  0.00762904],\n         [-0.04364663,  0.15338175, -0.10123171],\n         [ 0.2676707 ,  0.70861197, -0.46737352],\n         ...,\n         [ 0.8645493 ,  0.722528  , -0.60077596],\n         [-0.6732556 ,  0.5519895 , -0.6607604 ],\n         [ 0.06130024,  0.156236  , -0.6213455 ]]]], dtype=float32)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "averaged_samples = RandomWeightedAverage()([real_samples, generated_samples_for_discriminator])\n",
    "# averaged_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "gradients = compute_gradients(y_pred, [averaged_samples])[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wgan.train(epochs=10000, batch_size=batch_size, sample_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.save('./saved_model/wgangp32_gen_model.h5')\n",
    "gan.discriminator.save('./saved_model/wgangp32_critic_model.h5')\n",
    "# gan.combined.save('./saved_model/dcgan_wloss4_combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_34\n",
      "leaky_re_lu_61\n",
      "conv2d_35\n",
      "leaky_re_lu_62\n",
      "conv2d_36\n",
      "leaky_re_lu_63\n",
      "conv2d_37\n",
      "leaky_re_lu_64\n",
      "conv2d_38\n",
      "leaky_re_lu_65\n",
      "conv2d_39\n",
      "leaky_re_lu_66\n",
      "conv2d_40\n",
      "leaky_re_lu_67\n",
      "conv2d_41\n",
      "leaky_re_lu_68\n",
      "conv2d_42\n",
      "leaky_re_lu_69\n",
      "conv2d_43\n",
      "leaky_re_lu_70\n",
      "conv2d_44\n",
      "flatten_4\n"
     ]
    }
   ],
   "source": [
    "for layer in wgan.critic.layers[1].layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(int(math.log(self.img_rows / self.input_rows, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "list = [i for i in range(1, int(math.log(64 / 4, 2)) * 2, 2)]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8, -6, -4, -2]\n"
     ]
    }
   ],
   "source": [
    "list = [-i for i in range(int(math.log(64 / 4, 2)) * 2, 0, -2)]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]\n",
    "[-i for i in range(int(math.log(self.img_rows / self.input_rows, 2)) * 2, 0, -2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
