{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2h over -> 40min by Multi GPU!\n",
    "\n",
    "TASK\n",
    "2 GPUにしたとき、gradient_penaltyがおかしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Reshape, Flatten, Activation\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "import shutil, os, sys, io, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from functools import partial\n",
    "from itertools import zip_longest\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('/home/k_yonhon/py/Keras-GAN/pggan/')\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from tensor_board_logger import TensorBoardLogger\n",
    "from layer_visualizer import LayerVisualizer\n",
    "\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "\n",
    "gpu_count = 2\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples,\n",
    "                          gradient_penalty_weight):\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        # ---------------------\n",
    "        #  for log on TensorBoard\n",
    "        # ---------------------\n",
    "        target_dir = \"./my_log_dir\"\n",
    "        shutil.rmtree(target_dir, ignore_errors=True)\n",
    "        os.mkdir(target_dir)\n",
    "        self.logger = TensorBoardLogger(log_dir=target_dir)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Parameter\n",
    "        # ---------------------\n",
    "        self.resume = 0\n",
    "        \n",
    "        self.n_critic = 5\n",
    "        self.λ = 10\n",
    "        \n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        # self.img_batch_shape = (batch_size, self.img_rows, self.img_cols, self.channels)\n",
    "        self.input_rows = 4\n",
    "        self.input_cols = 4\n",
    "        self.latent_dim = 128  # Noiseの次元\n",
    "        # optimizer = Adam(lr=0.00001, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        # optimizer = Adam(lr=0.00005, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        optimizer = Adam(lr=0.0001, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        # optimizer = Adam(lr=0.0005, beta_1=0., beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Build model\n",
    "        # ---------------------\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            if self.resume == 0:\n",
    "                self.critic = self.build_critic()\n",
    "                self.generator = self.build_generator()\n",
    "            else:\n",
    "                self.critic = load_model('./saved_model/wgangp32_disc_model_'+str(self.resume)+'epoch.h5')\n",
    "                self.generator = load_model('./saved_model/wgangp32_gen_model_'+str(self.resume)+'epoch.h5')\n",
    "\n",
    "            #  Load pretrained weights\n",
    "            pre_gen = load_model('./saved_model/wgangp16_gen_model.h5')\n",
    "            for i, layer in enumerate(self.generator.layers[1].layers):\n",
    "                if i in [i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]:\n",
    "                    layer.set_weights(pre_gen.layers[1].layers[i].get_weights())\n",
    "\n",
    "            pre_critic = load_model('./saved_model/wgangp16_disc_model.h5')\n",
    "            for i, layer in enumerate(self.critic.layers[1].layers):\n",
    "                j = i - len(self.critic.layers[1].layers)\n",
    "                if j in [-i for i in range(int(math.log(self.img_rows / self.input_rows, 2)) * 2, 0, -2)]:\n",
    "                    layer.set_weights(pre_critic.layers[1].layers[j].get_weights())\n",
    "                    layer.trainable = False\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "     \n",
    "        generator_input_for_discriminator = Input(shape=(self.latent_dim,))\n",
    "        generated_samples_for_discriminator = self.generator(generator_input_for_discriminator)\n",
    "        discriminator_output_from_generator = self.critic(generated_samples_for_discriminator)\n",
    "        \n",
    "        real_samples = Input(shape=self.img_shape)        \n",
    "        discriminator_output_from_real_samples = self.critic(real_samples)\n",
    "\n",
    "        averaged_samples = Input(shape=self.img_shape)\n",
    "        averaged_samples_out = self.critic(averaged_samples)\n",
    "\n",
    "        partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                                  averaged_samples=averaged_samples,\n",
    "                                  gradient_penalty_weight=self.λ)\n",
    "        # Functions need names or Keras will throw an error\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "        self.critic_model = Model(inputs=[generator_input_for_discriminator, \n",
    "                                          real_samples,\n",
    "                                          averaged_samples],\n",
    "                                  outputs=[discriminator_output_from_generator, \n",
    "                                           discriminator_output_from_real_samples,\n",
    "                                           averaged_samples_out])\n",
    "        if gpu_count > 1:\n",
    "            self.critic_model = multi_gpu_model(self.critic_model, gpus=gpu_count)\n",
    "        self.critic_model.compile(optimizer=optimizer, \n",
    "                                  loss=[wasserstein_loss, \n",
    "                                        wasserstein_loss, \n",
    "                                        partial_gp_loss])\n",
    "        \n",
    "        print('Critic Summary:')\n",
    "        self.critic.summary()       \n",
    "        \n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "        for i, layer in enumerate(self.generator.layers[1].layers):\n",
    "            if i in [i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]:\n",
    "                layer.trainable = False\n",
    "                    \n",
    "        generator_input = Input(batch_shape=(batch_size, self.latent_dim))\n",
    "        generator_layers = self.generator(generator_input)\n",
    "        discriminator_layers_for_generator = self.critic(generator_layers)\n",
    "        \n",
    "        self.generator_model = Model(inputs=[generator_input], \n",
    "                                     outputs=[discriminator_layers_for_generator])\n",
    "        if gpu_count > 1:\n",
    "            self.generator_model = multi_gpu_model(self.generator_model, gpus=gpu_count)\n",
    "        self.generator_model.compile(optimizer=optimizer,\n",
    "                                     loss=wasserstein_loss)        \n",
    "\n",
    "        print('Genarator Summary:')\n",
    "        self.generator.summary()   \n",
    "   \n",
    "    def build_generator(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            model = Sequential()\n",
    "            model.add(Reshape((self.input_rows, self.input_cols, int(self.latent_dim / (self.input_rows * self.input_cols))), \n",
    "                              input_shape=(self.latent_dim,)\n",
    "                             ))\n",
    "\n",
    "            model.add(Conv2DTranspose(512, (3, 3), strides=1, padding='same',\n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))      \n",
    "\n",
    "            for _ in range(int(math.log(self.img_rows / self.input_rows, 2))):\n",
    "                model.add(Conv2DTranspose(512, (3, 3), strides=2, padding='same', \n",
    "                                         kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                         ))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(256, (3, 3), strides=1, padding='same', \n",
    "                                      kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                      ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(128, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(64, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(32, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(16, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2DTranspose(3, (3, 3), strides=1, padding='same', \n",
    "                                     kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                     ))                \n",
    "            model.add(Activation(\"tanh\"))\n",
    "\n",
    "            noise = Input(shape=(self.latent_dim,))\n",
    "            img = model(noise)\n",
    "            return Model(noise, img)\n",
    "    \n",
    "    def build_critic(self):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(16, (1, 1), strides=1, input_shape=self.img_shape, padding=\"valid\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(32, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(64, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(128, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(256, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(512, (3, 3), strides=1, padding=\"same\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            for _ in range(int(math.log(self.img_rows / self.input_rows, 2))):\n",
    "                model.add(Conv2D(512, (3, 3), strides=2, padding=\"same\",\n",
    "                                 kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                                ))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "            model.add(Conv2D(1, (4, 4), strides=1, padding=\"valid\",\n",
    "                             kernel_initializer=keras.initializers.Orthogonal(gain=1.4, seed=None),\n",
    "                            ))\n",
    "            model.add(Flatten())\n",
    "\n",
    "            img = Input(shape=self.img_shape)\n",
    "            validity = model(img)\n",
    "            return Model(img, validity)\n",
    "    \n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "        # ---------------------\n",
    "        #  Load the dataset\n",
    "        # ---------------------      \n",
    "        # Original dataset\n",
    "        X_train = np.load('../datasets/lfw32.npz')['arr_0']\n",
    "        X_train = X_train / 127.5 - 1.0   # Rescale -1 to 1\n",
    "        \n",
    "        epsilon = np.random.uniform(size = (batch_size, 1,1,1))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1), dtype=np.float32)\n",
    "        fake = np.ones((batch_size, 1), dtype=np.float32)\n",
    "        dummy = np.zeros((batch_size, 1), dtype=np.float32)\n",
    "        \n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        for epoch in tqdm(range(self.resume, self.resume + epochs + 1)):\n",
    "            for _ in range(self.n_critic):\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                \n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                               \n",
    "                # Mix real and genarate images\n",
    "                mix_imgs = epsilon * imgs + (1-epsilon) * gen_imgs\n",
    "                \n",
    "                # Train the critic\n",
    "                d_loss = self.critic_model.train_on_batch([noise, imgs, mix_imgs], \n",
    "                                                          [fake, valid, dummy])\n",
    "                # d_loss = d_loss[0]\n",
    "                \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            g_loss = self.generator.train_on_batch(noise, valid)\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Log on TensorBoard\n",
    "            # ---------------------\n",
    "            # Backup Model\n",
    "            # if epoch != 0 and epoch % 1000 == 0:\n",
    "            #     self.critic.save('./saved_model/wgangp32_disc_model_'+str(epoch+self.resume)+'epoch.h5')\n",
    "            #     self.generator.save('./saved_model/wgangp32_gen_model_'+str(epoch+self.resume)+'epoch.h5')\n",
    "            \n",
    "            # Save Loss & Histgram\n",
    "            logs = {\n",
    "                \"loss/Critic\": d_loss[0],\n",
    "                \"loss/Generator\": g_loss,\n",
    "                \"loss_Critic/D_gen\": d_loss[1],\n",
    "                \"loss_Critic/D_real\": -d_loss[2],\n",
    "                \"loss_Critic/gradient_penalty\": d_loss[3],\n",
    "                \"loss_Critic/total_loss\": d_loss[1] + d_loss[2] + d_loss[3],                \n",
    "            }\n",
    "\n",
    "            histograms = {}\n",
    "            for layer in self.critic.layers[1].layers:\n",
    "                for i in range(len(layer.get_weights())):\n",
    "                    if \"conv\" in layer.name or \"dense\" in layer.name:\n",
    "                        name = layer.name + \"/\" + str(i)\n",
    "                        value = layer.get_weights()[i]\n",
    "                        histograms[name] = value\n",
    "            self.logger.log(logs=logs, histograms=histograms, epoch=epoch+self.resume)\n",
    "            \n",
    "            # Save generated image samples\n",
    "            if epoch+self.resume == 1000 or epoch+self.resume == 2000 or (epoch+self.resume) % sample_interval == 0:\n",
    "                fig, name = self.sample_images(epoch+self.resume)\n",
    "                images = {name: fig}\n",
    "                self.logger.log(images=images, epoch=epoch+self.resume)\n",
    "                print(\"%d [C loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = ((0.5 * gen_imgs + 0.5) * 255).astype(np.uint8)\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                if self.channels == 1:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap=\"gray\")\n",
    "                else:\n",
    "                    axs[i, j].imshow(gen_imgs[cnt, :, :, :self.channels], cmap=\"gray\")\n",
    "                axs[i, j].axis(\"off\")\n",
    "                cnt += 1\n",
    "        name = str(epoch) + \".png\"\n",
    "        return fig, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic Summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 1)                 8660001   \n",
      "=================================================================\n",
      "Total params: 8,660,001\n",
      "Trainable params: 3,932,192\n",
      "Non-trainable params: 4,727,809\n",
      "_________________________________________________________________\n",
      "Genarator Summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sequential_10 (Sequential)   (None, 32, 32, 3)         8689059   \n",
      "=================================================================\n",
      "Total params: 8,689,059\n",
      "Trainable params: 3,932,067\n",
      "Non-trainable params: 4,756,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wgan = WGANGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected size[0] in [0, 32], but got 64\n\t [[{{node replica_0_3/lambda_15/Slice}} = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_12_0_0/_203, replica_0_3/lambda_15/mul_1, replica_0_3/lambda_15/concat)]]\n\t [[{{node replica_0_3/model_11/model_7/sequential_3/flatten_2/Reshape/_369}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_384_replica_0_3/model_11/model_7/sequential_3/flatten_2/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-251a9c09d843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-bd97d22c412e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mnoise_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgpu_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected size[0] in [0, 32], but got 64\n\t [[{{node replica_0_3/lambda_15/Slice}} = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_12_0_0/_203, replica_0_3/lambda_15/mul_1, replica_0_3/lambda_15/concat)]]\n\t [[{{node replica_0_3/model_11/model_7/sequential_3/flatten_2/Reshape/_369}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_384_replica_0_3/model_11/model_7/sequential_3/flatten_2/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "wgan.train(epochs=10000, batch_size=batch_size, sample_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.save('./saved_model/wgangp32_gen_model.h5')\n",
    "gan.critic.save('./saved_model/wgangp32_critic_model.h5')\n",
    "# gan.combined.save('./saved_model/dcgan_wloss4_combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_34\n",
      "leaky_re_lu_61\n",
      "conv2d_35\n",
      "leaky_re_lu_62\n",
      "conv2d_36\n",
      "leaky_re_lu_63\n",
      "conv2d_37\n",
      "leaky_re_lu_64\n",
      "conv2d_38\n",
      "leaky_re_lu_65\n",
      "conv2d_39\n",
      "leaky_re_lu_66\n",
      "conv2d_40\n",
      "leaky_re_lu_67\n",
      "conv2d_41\n",
      "leaky_re_lu_68\n",
      "conv2d_42\n",
      "leaky_re_lu_69\n",
      "conv2d_43\n",
      "leaky_re_lu_70\n",
      "conv2d_44\n",
      "flatten_4\n"
     ]
    }
   ],
   "source": [
    "for layer in wgan.critic.layers[1].layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(int(math.log(self.img_rows / self.input_rows, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "list = [i for i in range(1, int(math.log(64 / 4, 2)) * 2, 2)]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8, -6, -4, -2]\n"
     ]
    }
   ],
   "source": [
    "list = [-i for i in range(int(math.log(64 / 4, 2)) * 2, 0, -2)]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1, int(math.log(self.img_rows / self.input_rows, 2)) * 2, 2)]\n",
    "[-i for i in range(int(math.log(self.img_rows / self.input_rows, 2)) * 2, 0, -2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (128, wgan.latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "gen_imgs = wgan.generator.predict(noise)\n",
    "print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1)\n"
     ]
    }
   ],
   "source": [
    "gen_imgs = wgan.generator_model.predict(noise, batch_size=128)\n",
    "print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25049707], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../datasets/lfw32.npz')['arr_0']\n",
    "X_train = X_train / 127.5 - 1.0   # Rescale -1 to 1\n",
    "idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "imgs = X_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[[[-1.        , -1.        , -1.        ],\n         [-0.82745098, -0.78823529, -0.76470588],\n         [-0.81960784, -0.78039216, -0.75686275],\n         ...,\n         [-0.80392157, -0.80392157,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-71375edbee72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[[[-1.        , -1.        , -1.        ],\n         [-0.82745098, -0.78823529, -0.76470588],\n         [-0.81960784, -0.78039216, -0.75686275],\n         ...,\n         [-0.80392157, -0.80392157,..."
     ]
    }
   ],
   "source": [
    "gen_imgs = wgan.critic_model.predict(imgs)\n",
    "print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
